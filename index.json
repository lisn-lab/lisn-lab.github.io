
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Hi! My name is Daisy. I’m a second-year Psychology and Linguistics Undergraduate student at Lancaster University and a member of the S.T.A.R.S team within the LISN lab. My role within the lab is contributing to the NICE community building project by studying a range of unique manifestations of inner speech, or lack thereof, and engaging others with unique perspectives in this work. As a student of both psychology and linguistics, I am fascinated by any study of language in the mind! I hope to build a career researching what occurs in the mind during communication in order to apply this to help those who struggle with communication.\n","date":1738281600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1738281600,"objectID":"272329944ba0a39ba98bd7e96a17a092","permalink":"https://lisn-lab.org/author/daisy-watson/","publishdate":"2025-01-31T00:00:00Z","relpermalink":"/author/daisy-watson/","section":"authors","summary":"Hi! My name is Daisy. I’m a second-year Psychology and Linguistics Undergraduate student at Lancaster University and a member of the S.T.A.R.S team within the LISN lab. My role within the lab is contributing to the NICE community building project by studying a range of unique manifestations of inner speech, or lack thereof, and engaging others with unique perspectives in this work. As a student of both psychology and linguistics, I am fascinated by any study of language in the mind! I hope to build a career researching what occurs in the mind during communication in order to apply this to help those who struggle with communication.\n","tags":null,"title":"Daisy Watson","type":"authors"},{"authors":null,"categories":null,"content":"Hi, my name is Madison and I’m a second-year psychology student at Lancaster University. As a member of the S.T.A.R.S team in the LISN lab, I am currently assisting in the NICE community building project and in research on inner speech \u0026amp; Aphantasia. My main research interest is in the neural mechanisms of inner speech, particularly identifying the contributions of different brain regions and how these interact with one another. In the future, I hope to build a research career in neuroscience to help advance our knowledge and understanding of brain function and improve the health \u0026amp; lives of many.\n","date":1737417600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1737417600,"objectID":"b1507cd404008a79775fab1d32036213","permalink":"https://lisn-lab.org/author/madison-hartley/","publishdate":"2025-01-21T00:00:00Z","relpermalink":"/author/madison-hartley/","section":"authors","summary":"Hi, my name is Madison and I’m a second-year psychology student at Lancaster University. As a member of the S.T.A.R.S team in the LISN lab, I am currently assisting in the NICE community building project and in research on inner speech \u0026 Aphantasia. My main research interest is in the neural mechanisms of inner speech, particularly identifying the contributions of different brain regions and how these interact with one another. In the future, I hope to build a research career in neuroscience to help advance our knowledge and understanding of brain function and improve the health \u0026 lives of many.\n","tags":null,"title":"Madison Hartley","type":"authors"},{"authors":null,"categories":null,"content":"I am a Senior Lecturer (Associate Professor) at the Department of Psychology at Lancaster University, United Kingdom. My research focuses on the cognitive neuroscience of language and inner speech. My recent work concentrates on neural mechanisms of inner speech and voice hearing, abstract concept processing, and eye movements in reading. I also explore topics like bilingualism and self-awareness, using methods such as EEG, s/fMRI, eye tracking, neurostimulation, and computational modelling.\nMy work is funded by the Economic and Social Research Council, Medical Research Council, The Royal Society, The Bial Foundation, The British Academy and the Experimental Psychological Society.\n","date":1736121600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1736121600,"objectID":"ed0ccd63a82b4a29db8d2289861d99e5","permalink":"https://lisn-lab.org/author/bo-yao/","publishdate":"2025-01-06T00:00:00Z","relpermalink":"/author/bo-yao/","section":"authors","summary":"I am a Senior Lecturer (Associate Professor) at the Department of Psychology at Lancaster University, United Kingdom. My research focuses on the cognitive neuroscience of language and inner speech. My recent work concentrates on neural mechanisms of inner speech and voice hearing, abstract concept processing, and eye movements in reading. I also explore topics like bilingualism and self-awareness, using methods such as EEG, s/fMRI, eye tracking, neurostimulation, and computational modelling.\n","tags":null,"title":"Bo Yao","type":"authors"},{"authors":null,"categories":null,"content":"Dr Jaydan Pratts was a PhD student at the LISN lab. His PhD thesis explores inner speech, a speech-like experience without sound, aiming to develop an integrated model that accounts for its diverse nature. Various experimental techniques, including fMRI meta-analysis and transcranial magnetic stimulation, were used to investigate the brain regions involved in inner speech and its connections with speech production and perception. The research findings revealed a complex interaction between different inner speech phenomena. Jaydan now works as a data engineering in the tech industry.\n","date":1695945600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1695945600,"objectID":"d1a2869507b4ced5336e15c4739ac5a6","permalink":"https://lisn-lab.org/author/jaydan-pratts/","publishdate":"2023-09-29T00:00:00Z","relpermalink":"/author/jaydan-pratts/","section":"authors","summary":"Dr Jaydan Pratts was a PhD student at the LISN lab. His PhD thesis explores inner speech, a speech-like experience without sound, aiming to develop an integrated model that accounts for its diverse nature. Various experimental techniques, including fMRI meta-analysis and transcranial magnetic stimulation, were used to investigate the brain regions involved in inner speech and its connections with speech production and perception. The research findings revealed a complex interaction between different inner speech phenomena. Jaydan now works as a data engineering in the tech industry.\n","tags":null,"title":"Jaydan Pratts","type":"authors"},{"authors":null,"categories":null,"content":"Dr Briony Banks is a cognitive psychologist specialising in speech and language. She researches how language interacts with our perception, actions and cognition, for example how language comprehension is related to our sensory experiences and actions, and how we integrate multimodal cues when we communicate with others. She previously worked as a Postdoctoral Research Associate on an ESRC project on inner speech at the LISN lab. She then progressed to a Senior Research Associate on an ERC grant investigating how language and sensorimotor experience interact during complex cognitive processes such as semantic categorisation and memory for actions. She now works as a Senior Research Scientist at Ambition Institute. Her particular interests include how we understand abstract words, multisensory speech perception and inner speech/language. She uses a range of methods from experimental psychology, psycholinguistics and cognitive neuroscience.\n","date":1633046400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1633046400,"objectID":"5f819e1db82aebe70b85cccf38438ff3","permalink":"https://lisn-lab.org/author/briony-banks/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/author/briony-banks/","section":"authors","summary":"Dr Briony Banks is a cognitive psychologist specialising in speech and language. She researches how language interacts with our perception, actions and cognition, for example how language comprehension is related to our sensory experiences and actions, and how we integrate multimodal cues when we communicate with others. She previously worked as a Postdoctoral Research Associate on an ESRC project on inner speech at the LISN lab. She then progressed to a Senior Research Associate on an ERC grant investigating how language and sensorimotor experience interact during complex cognitive processes such as semantic categorisation and memory for actions. She now works as a Senior Research Scientist at Ambition Institute. Her particular interests include how we understand abstract words, multisensory speech perception and inner speech/language. She uses a range of methods from experimental psychology, psycholinguistics and cognitive neuroscience.\n","tags":null,"title":"Briony Banks","type":"authors"},{"authors":null,"categories":null,"content":"Hello! I am a third year undergraduate psychology student who’s particularly interested in developmental psychology \u0026amp; neuroscience particularly the development of inner speech and language. I am currently a research assistant using EEGs to look at the lack of inner speech (anendophasia). In the future, I hope to pursue my passions further with a masters in educational neuroscience.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"6d30047e5c8becc556fd823e40651db7","permalink":"https://lisn-lab.org/author/amelia-simmonds/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/amelia-simmonds/","section":"authors","summary":"Hello! I am a third year undergraduate psychology student who’s particularly interested in developmental psychology \u0026 neuroscience particularly the development of inner speech and language. I am currently a research assistant using EEGs to look at the lack of inner speech (anendophasia). In the future, I hope to pursue my passions further with a masters in educational neuroscience.\n","tags":null,"title":"Amelia Simmonds","type":"authors"},{"authors":null,"categories":null,"content":"Hi! My name is Chloe and I am a 3rd year exchange student from McMaster University in Hamilton, Canada where I study psychology, neuroscience, and behaviour. In addition to investigating literature on inner speech, I am working with Polhemus to use the digitization device for EEG research. I am very interested in neuroscience, especially neurological differences in those with abnormal psychology. I plan to pursue a Master’s and PhD in psychology and neuroscience.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ae13e5c5c8595eb024b1dc19a0d9943c","permalink":"https://lisn-lab.org/author/chloe-taylor/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/chloe-taylor/","section":"authors","summary":"Hi! My name is Chloe and I am a 3rd year exchange student from McMaster University in Hamilton, Canada where I study psychology, neuroscience, and behaviour. In addition to investigating literature on inner speech, I am working with Polhemus to use the digitization device for EEG research. I am very interested in neuroscience, especially neurological differences in those with abnormal psychology. I plan to pursue a Master’s and PhD in psychology and neuroscience.\n","tags":null,"title":"Chloe Taylor","type":"authors"},{"authors":null,"categories":null,"content":"El is on a 1+3 ESRC Studentship to study the effects of noise on the development of inner speech and cognition in classroom settings.\nShe is main-supervised by Dr Hannah Stewart of the PELiCAN Lab.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"fecee17bc1e970137eecb5e0ef9eb448","permalink":"https://lisn-lab.org/author/el-smith/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/el-smith/","section":"authors","summary":"El is on a 1+3 ESRC Studentship to study the effects of noise on the development of inner speech and cognition in classroom settings.\nShe is main-supervised by Dr Hannah Stewart of the PELiCAN Lab.\n","tags":null,"title":"El Smith","type":"authors"},{"authors":null,"categories":null,"content":"Hi, My name is Findlay and I am in my first year of studying psychology. I am currently a research assistant studying the motor and perceptual mechanisms of inner speech as a member of the STARS team in the Inner Speech, Language and Neuroscience lab. My main interest in neuroscience is the effect of drugs on the brain and psychopathology and I intend to pursue psychology either in research or in a clinical setting. However, in my free time I like to read, run and practice sports like kickboxing.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"ce87d2b83cc517586ee2ba2f16affa67","permalink":"https://lisn-lab.org/author/findlay-copeland/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/findlay-copeland/","section":"authors","summary":"Hi, My name is Findlay and I am in my first year of studying psychology. I am currently a research assistant studying the motor and perceptual mechanisms of inner speech as a member of the STARS team in the Inner Speech, Language and Neuroscience lab. My main interest in neuroscience is the effect of drugs on the brain and psychopathology and I intend to pursue psychology either in research or in a clinical setting. However, in my free time I like to read, run and practice sports like kickboxing.\n","tags":null,"title":"Findlay Copeland","type":"authors"},{"authors":null,"categories":null,"content":"Ms Guyu Shen is a PhD candidate at the LISN lab. Her PhD project explores the complex nature of abstract concepts, focusing on how they are grounded in multimodal information, particularly in the episodic memory system. The research includes a series of experiments that test current theories, determine the extent to which abstract concepts rely on contextual information, and investigate the interplay between semantic and episodic memory in concrete and abstract concept processing.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"958713189f4862611df474cd9067b23f","permalink":"https://lisn-lab.org/author/guyu-shen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/guyu-shen/","section":"authors","summary":"Ms Guyu Shen is a PhD candidate at the LISN lab. Her PhD project explores the complex nature of abstract concepts, focusing on how they are grounded in multimodal information, particularly in the episodic memory system. The research includes a series of experiments that test current theories, determine the extent to which abstract concepts rely on contextual information, and investigate the interplay between semantic and episodic memory in concrete and abstract concept processing.\n","tags":null,"title":"Guyu Shen","type":"authors"},{"authors":null,"categories":null,"content":"Ms Jiaqi Wang began her PhD studies at Lancaster University in October 2024. She will spend her first year at the LISN Lab and continue her work at the Emotion and Communication Lab for the remainder of her PhD. Her research interests centre around the cognitive mechanisms of visual metaphor. She seeks to understand why and how different types of visual metaphor constructions (e.g., juxtaposition, replacement, and fusion), as well as the concreteness of their constituents (concrete, abstract), have varying impacts on conceptualisation. Additionally, she aims to explore why certain types of visual metaphors are more consistently understood than others.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"e397f358270c095b6cee348f70e2f3ee","permalink":"https://lisn-lab.org/author/jiaqi-wang/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jiaqi-wang/","section":"authors","summary":"Ms Jiaqi Wang began her PhD studies at Lancaster University in October 2024. She will spend her first year at the LISN Lab and continue her work at the Emotion and Communication Lab for the remainder of her PhD. Her research interests centre around the cognitive mechanisms of visual metaphor. She seeks to understand why and how different types of visual metaphor constructions (e.g., juxtaposition, replacement, and fusion), as well as the concreteness of their constituents (concrete, abstract), have varying impacts on conceptualisation. Additionally, she aims to explore why certain types of visual metaphors are more consistently understood than others.\n","tags":null,"title":"Jiaqi Wang","type":"authors"},{"authors":null,"categories":null,"content":"Ms Jiaxuan, a PhD candidate at the LISN lab, is studying bilingualism, with a focus on structural processing and perspective-taking in Mandarin, a topic-prominent language, and in English, a subject-prominent language. Her research examines how the omission of sentence subjects and the nuanced use of passives in Mandarin influence structural processing and perspectives in mental representations. Her thesis aims to shed new light into the complex relationship between language structure, mental perspectives, and how these elements are expressed differently in topic-prominent versus subject-prominent languages.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"757ba64deeb9b17047674b011cfd1b68","permalink":"https://lisn-lab.org/author/jiaxuan-chen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/jiaxuan-chen/","section":"authors","summary":"Ms Jiaxuan, a PhD candidate at the LISN lab, is studying bilingualism, with a focus on structural processing and perspective-taking in Mandarin, a topic-prominent language, and in English, a subject-prominent language. Her research examines how the omission of sentence subjects and the nuanced use of passives in Mandarin influence structural processing and perspectives in mental representations. Her thesis aims to shed new light into the complex relationship between language structure, mental perspectives, and how these elements are expressed differently in topic-prominent versus subject-prominent languages.\n","tags":null,"title":"Jiaxuan Chen","type":"authors"},{"authors":null,"categories":null,"content":"Laura Johnson is a PhD candidate at the University of Manchester, and is affiliated with the LISN lab. Her PhD research uses computational models to explore how psychological factors alter prior expectations and influence verbally induced hallucinations in both general and clinical populations.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"bab7ba33b2a2d357fb80cce03283987d","permalink":"https://lisn-lab.org/author/laura-johnson/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/laura-johnson/","section":"authors","summary":"Laura Johnson is a PhD candidate at the University of Manchester, and is affiliated with the LISN lab. Her PhD research uses computational models to explore how psychological factors alter prior expectations and influence verbally induced hallucinations in both general and clinical populations.\n","tags":null,"title":"Laura Johnson","type":"authors"},{"authors":null,"categories":null,"content":"Hello! I am an undergraduate Psychology student at Lancaster University working in the Language, Inner Speech and Neuroscience (LISN) Lab as a Research Assistant, as well as being a Psychology Ambassador for the University. My role includes aiding the lab with data collection of research with individuals with Anendophasia. I really enjoy neuroscience, I am especially interested in the influence drugs and external substances can have on the neurochemistry of the brain, especially those with psychological disorders!\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"948a69e235d3ccd379b3faa4ce1118c8","permalink":"https://lisn-lab.org/author/maisie-dransfield/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/maisie-dransfield/","section":"authors","summary":"Hello! I am an undergraduate Psychology student at Lancaster University working in the Language, Inner Speech and Neuroscience (LISN) Lab as a Research Assistant, as well as being a Psychology Ambassador for the University. My role includes aiding the lab with data collection of research with individuals with Anendophasia. I really enjoy neuroscience, I am especially interested in the influence drugs and external substances can have on the neurochemistry of the brain, especially those with psychological disorders!\n","tags":null,"title":"Maisie Dransfield","type":"authors"},{"authors":null,"categories":null,"content":"Olivia Mak is a PhD Candidate at the LISN lab, now in her final year. Her research investigates how the brain’s predictive mechanisms for speaking and hearing might induce auditory verbal hallucinations in nonclinical populations. Using behavioural methods like conditioning target sounds with visual cues, introducing earworms, or asking people to count out loud during signal detection tasks, she aims to see if altering these predictions can change the false positive detection of non-existent target sounds amidst background noise. Her work helps deepen our understanding of auditory verbal hallucinations across the population spectrum.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"82b58c112e12582018dd5726ae13a48f","permalink":"https://lisn-lab.org/author/olivia-mak/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/olivia-mak/","section":"authors","summary":"Olivia Mak is a PhD Candidate at the LISN lab, now in her final year. Her research investigates how the brain’s predictive mechanisms for speaking and hearing might induce auditory verbal hallucinations in nonclinical populations. Using behavioural methods like conditioning target sounds with visual cues, introducing earworms, or asking people to count out loud during signal detection tasks, she aims to see if altering these predictions can change the false positive detection of non-existent target sounds amidst background noise. Her work helps deepen our understanding of auditory verbal hallucinations across the population spectrum.\n","tags":null,"title":"Olivia Mak","type":"authors"},{"authors":null,"categories":null,"content":"Dr Ryan Horsfall was a Postdoctoral Research Associate at the LISN lab from 2019 to 2021. He worked on projects funded by the ESRC and the Bial Foundation, investigating the behavioural correlates, emotional impacts, and neural mechanisms of inner speech through experiments using EEG, fMRI, behavioural paradigms, and eye tracking. After his time at LISN, Ryan became a Teaching Associate at the University of Sheffield and is now a clinical psychologist with the NHS. His research interests include cognitive neuroscience, language, perception, emotional judgments, speech processing, and auditory-verbal hallucinations.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"1c3e01d7959ed9504cb2ff1d6731c591","permalink":"https://lisn-lab.org/author/ryan-horsfall/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ryan-horsfall/","section":"authors","summary":"Dr Ryan Horsfall was a Postdoctoral Research Associate at the LISN lab from 2019 to 2021. He worked on projects funded by the ESRC and the Bial Foundation, investigating the behavioural correlates, emotional impacts, and neural mechanisms of inner speech through experiments using EEG, fMRI, behavioural paradigms, and eye tracking. After his time at LISN, Ryan became a Teaching Associate at the University of Sheffield and is now a clinical psychologist with the NHS. His research interests include cognitive neuroscience, language, perception, emotional judgments, speech processing, and auditory-verbal hallucinations.\n","tags":null,"title":"Ryan Horsfall","type":"authors"},{"authors":null,"categories":null,"content":"Hello! My name is Shalom. I am a third year psychology student at Lancaster university, currently working with the LISN lab as a research assistant. My passion in inner speech studies is developed from all my daily inner conversations with myself and how they affect me. An interesting one would be telling myself to “JUMP HIGHER!!!” whenever I am practicing doing a backflip and it’s quite helpful. Apart from flips, I also love reading novels, especially fantasy books, which require a little bit of imagination to enjoy the story. Look forward to the future, I want to finish a PhD and become a clinical psychologist and continue investigating possible therapeutic approaches from inner speech on mental disorders.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"8bab6b0b5337f5d2aa185aefc0f54210","permalink":"https://lisn-lab.org/author/sa-lun-yuen/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/sa-lun-yuen/","section":"authors","summary":"Hello! My name is Shalom. I am a third year psychology student at Lancaster university, currently working with the LISN lab as a research assistant. My passion in inner speech studies is developed from all my daily inner conversations with myself and how they affect me. An interesting one would be telling myself to “JUMP HIGHER!!!” whenever I am practicing doing a backflip and it’s quite helpful. Apart from flips, I also love reading novels, especially fantasy books, which require a little bit of imagination to enjoy the story. Look forward to the future, I want to finish a PhD and become a clinical psychologist and continue investigating possible therapeutic approaches from inner speech on mental disorders.\n","tags":null,"title":"Sa Lun Yuen","type":"authors"},{"authors":null,"categories":null,"content":"Hello! My name is Summer, I am a first-year student and part of the STARS team in the Language, Inner Speech, and Neuroscience Lab. I live at home with my three cats and a dog, who are always by my side as I focus on my studies. My main research interest is “zoning out” in inner speech, exploring whether this experience might have benefits. In my free time, I enjoy reading, horse riding, and baking new recipes to share with friends and family. I hope to pursue a PhD and eventually become a professor, continuing my path in research.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"b17b0f1e83812d53e800537ef6960c80","permalink":"https://lisn-lab.org/author/summer-rickard/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/summer-rickard/","section":"authors","summary":"Hello! My name is Summer, I am a first-year student and part of the STARS team in the Language, Inner Speech, and Neuroscience Lab. I live at home with my three cats and a dog, who are always by my side as I focus on my studies. My main research interest is “zoning out” in inner speech, exploring whether this experience might have benefits. In my free time, I enjoy reading, horse riding, and baking new recipes to share with friends and family. I hope to pursue a PhD and eventually become a professor, continuing my path in research.\n","tags":null,"title":"Summer Rickard","type":"authors"},{"authors":null,"categories":null,"content":"Yanxi Lu is a PhD student working on the effect of culture and language emotional engagement during language comprehension. She is main supervised by Dr Francesca Citron of the Emotion and Communication Lab.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"792b596741939a4e6211ceffdb9bbd40","permalink":"https://lisn-lab.org/author/yanxi-lu/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/yanxi-lu/","section":"authors","summary":"Yanxi Lu is a PhD student working on the effect of culture and language emotional engagement during language comprehension. She is main supervised by Dr Francesca Citron of the Emotion and Communication Lab.\n","tags":null,"title":"Yanxi Lu","type":"authors"},{"authors":null,"categories":null,"content":" Table of Contents Abstract Concepts Structural Processing Eye Movements in Reading Language and Emotion At LISN, we investigate language processing through multiple complementary lenses, from fundamental cognitive mechanisms to complex emotional interactions. Our research spans four key areas: the representation of abstract concepts, structural processing within and across languages, eye movements during reading, and the interaction between language and emotion. Through this multi-faceted approach, we aim to develop a comprehensive understanding of how humans process, comprehend, and experience language. Our work combines diverse methodologies - from precise eye-tracking measurements to cognitive-behavioral studies - enabling us to examine language processing at various levels of analysis. Abstract Concepts Abstract concepts like “love” or “trust” pose a unique challenge in cognitive science. Unlike concrete concepts such as “red,” which derive meaning from direct sensory experiences, abstract concepts lack physical referents. This absence raises questions about how such concepts are represented in the mind and complicates the prevailing ’embodied’ theory of concept representation, which suggests that concepts gain meaning through bodily experiences.\nAt LISN, we tackle these challenges by exploring alternative grounding for abstract concepts. We investigate whether emotional or metaphorical experiences provide the basis for understanding abstract words. For example, ’trust’ is often considered a ‘big’ concept because it elicits strong emotions (Yao et al., 2013) and is metaphorically associated with large objects like ‘castle’ or ‘cathedral’ (Yao, Taylor, \u0026amp; Sereno, 2022). Our research also examines the possibility that abstract concepts have a more episodic and context-dependent grounding compared to concrete ones. For instance, the concept of ’love’ can vary significantly depending on the context, such as a romantic dinner or a care home, unlike more concrete concepts like ‘cat,’ which consistently evoke features like fur and paws. We extend this inquiry to understand how embodied experiences influence language comprehension across various contexts and life stages. Structural Processing Structural processing in language is a complex cognitive function that extends beyond mere syntax. It involves breaking down sentences into components such as subjects, verbs, and objects, and understanding their interrelationships to extract meaning. This function also intersects with other cognitive domains like prosody - the intonation in spoken sentences - and arithmetic operations, highlighting its role as a domain-general mechanism crucial for structuring language, cognition, and communication.\nAt LISN, our focus is twofold. First, we explore the link between implicit prosody in reading, commonly known as “inner speech,” and syntactic processing. This helps us understand how the ‘melody’ of language in our minds influences sentence interpretation (Yao \u0026amp; Scheepers, 2018). Second, we study how sentence structures in different languages affect cognition among their speakers. For example, Chinese sentences often omit subjects and focus on topics, whereas English sentences require subjects and emphasise them. This difference could lead to varying attentional focuses and mental representations. We also examine the contrasting structures between left-branching languages like Chinese and right-branching languages like English, suggesting different structural hierarchies between languages. Through these investigations, we aim to untangle the complexities of structural processing and its influence on cognition and communication. Eye Movements in Reading Eye movements in reading offer a rich data source for understanding cognitive processes such as attention, memory, and language comprehension. Captured through eye-tracking technology, these movements include quick jumps called saccades and brief pauses known as fixations, where most information absorption takes place. Factors like text complexity and reader familiarity affect the duration of these fixations and the length of saccades. The parafoveal region of the eye also provides a ‘preview’ of upcoming words during saccades, facilitating smoother reading. Lexical variables such as word frequency, predictability, and orthography further influence these eye movements, offering insights into ocular control and cognitive processes in reading.\nAt LISN, we engage in targeted research projects to explore this complex landscape. For instance, one study examines the interaction between word frequency and contextual predictability in relation to parafoveal preview, aiming to understand their combined impact on fixation durations (Sereno et al., 2018). Another research line investigates how altering the perceptual quality of the parafoveal preview might affect the processing of the previewed word’s spelling, subsequently influencing lexical selection in later fixations. Through these …","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"c03b8195573d7eecdef4a0473bfd87b2","permalink":"https://lisn-lab.org/research/language/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/research/language/","section":"research","summary":"Language serves as a fundamental medium through which we encode our thoughts, emotions, and experiences. By studying the properties and functions of language, we can unravel how human experiences are intricately encoded and transformed through symbolic operations.","tags":["Abstract Concepts","Structural Processing","Eye movements","Emotion"],"title":"Language","type":"research"},{"authors":null,"categories":null,"content":" Table of Contents Varieties of Inner Speech Hearing Words off the Page Neural Mechanisms of Inner Speech Inner Speech in Self-Consciousness Inner speech represents a fundamental aspect of human cognition and consciousness, manifesting in various forms and serving multiple functions in mental life. At LISN, we investigate this phenomenon through multiple complementary approaches: examining its varieties and manifestations, studying its role in reading comprehension, mapping its neural underpinnings, and exploring its contribution to consciousness and self-awareness. This comprehensive approach allows us to build a deeper understanding of how inner speech shapes human thought and experience. Varieties of Inner Speech Inner speech encompasses distinct varieties, each serving unique cognitive functions. Dialogic inner speech enables internal conversations where multiple perspectives are mentally represented, while condensed inner speech operates in abbreviated thought patterns without full syntactic structure. Evaluative inner speech facilitates self-reflection and assessment, and motivational inner speech serves to regulate behavior and emotional states. These varieties differ not only in their form but also in their cognitive and behavioral impacts. Understanding these distinctions is crucial for comprehending how inner speech supports various mental processes, from problem-solving to emotional regulation.\nAt LISN, we employ multiple complementary methods to investigate these inner speech varieties. Through experience sampling, we capture real-time manifestations of different inner speech types across various cognitive tasks. Our innovative combination of think-aloud protocols with advanced EEG analysis helps identify distinct neural signatures for different inner speech subtypes. By applying machine learning techniques to these neural patterns, we’re developing new frameworks for understanding how different forms of inner speech contribute to cognitive processing. Through these research avenues, LISN aims to establish a comprehensive taxonomy of inner speech varieties and their roles in human cognition. Hearing Words off the Page When reading direct speech, many people report experiencing vivid inner voices, complete with distinctive tones, accents, and emotional qualities. This phenomenon represents a specialized manifestation of inner speech that bridges written language and auditory experience. The vividness of these inner voices can vary based on factors such as emotional engagement with the text, reading proficiency, and individual differences in cognitive style. This experience often enhances text comprehension and memory retention, particularly for dialogue-rich narratives.\nAt LISN, our research has revealed the sophisticated neural and cognitive mechanisms underlying this phenomenon. Our groundbreaking studies have demonstrated increased neural activity in the auditory cortex during silent reading of direct speech (Yao, Belin, \u0026amp; Scheepers, 2011), accompanied by synchronous auditory cortical oscillations (Yao et al., 2021). We’ve also found that eye movements during reading align with the natural rhythm of the imagined inner voice (Yao \u0026amp; Scheepers, 2011). Our current research explores how early experiences of learning to read aloud might establish automatic links between text and auditory experiences, and how inner voice simulation might serve as a prosocial mechanism reinforced by the brain’s reward system (Alderson-Day et al., 2020). Neural Mechanisms of Inner Speech The neural architecture supporting inner speech involves a sophisticated network of brain regions working in concert. This network encompasses multiple circuits, including speech production mechanisms (involving motor planning, coordination, and execution areas) and speech perception mechanisms (involving various temporal and parietal regions that support phonological and semantic processing). These core circuits interact dynamically with areas responsible for memory, attention, and emotional processing, creating a complex neural symphony that enables various forms of inner speech.\nAt LISN, our research focuses on understanding these neural mechanisms and how they support inner speech’s diverse phenomenology. We’ve highlighted the rhythmic nature of inner speech (Yao, 2025) by observing increased neural activity in auditory regions associated with speech prosody (Yao, Belin, \u0026amp; Scheepers, 2011) and more synchronous auditory cortical oscillations (Yao et al., 2021). Our recent meta-analysis (Pratts, Pobric, \u0026amp; Yao, 2023) suggests that inner speech may be supported by both a motor-driven pathway involving speech production circuits and an auditory pathway engaging perceptual mechanisms, potentially underpinning different inner speech subtypes. We are also employing machine learning to identify the neural features that characterise these subtypes, aiming for a more nuanced understanding of inner speech and its role in cognition. Through …","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"d643905475caf054acccb532ab26a070","permalink":"https://lisn-lab.org/research/innerspeech/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/research/innerspeech/","section":"research","summary":"Inner speech, the silent voice in our minds, is an enigmatic conscious experience where the brain engages in a dialogue with itself. Why and how does the brain reflect on itself and interact with the world through language, and why is this ability not experienced universally by all individuals?","tags":["speech quotation","inner speech subtypes","auditory cortex","neural oscillations","self-processing"],"title":"Inner Speech","type":"research"},{"authors":null,"categories":null,"content":" Table of Contents Voice Hearing Continuum Voice Hearing as Predictions Voice Hearing Transition Risks Voice Hearing Interventions Voice hearing research spans multiple interconnected domains, from understanding its prevalence in the general population to developing innovative interventions. At LISN, we take a comprehensive approach to studying this complex phenomenon. Our research examines voice hearing across four key areas: its existence as a continuous spectrum in the population, the critical factors influencing transition to clinical conditions, the underlying predictive mechanisms in the brain, and the development of novel therapeutic interventions. By investigating these interrelated aspects, we aim to advance both theoretical understanding and practical treatments for voice hearing experiences. Voice Hearing Continuum Voice hearing exists on a spectrum and is not limited to clinical populations. It involves a range of experiences, from hearing one’s name to complex dialogues, and can be distressing or benign. This natural variation in human experience has been studied through neuroscientific and psychological approaches, exploring its neural and cognitive correlates, while cultural factors also play a role. Understanding this spectrum has implications for mental health treatment, challenging associated stigma and informing therapeutic interventions.\nAt LISN, our research focuses on cognitive abilities and biases predictive of voice hearing tendencies across this spectrum. We particularly examine signal detection theory (SDT) performance, where both nonclinical and clinical voice hearers often exhibit an externalising bias, perceiving internal voices as originating externally. Through rigorous experimental methods, we compare SDT performance among individuals to understand how this bias may be influenced by auditory verbal hallucination (AVH) proneness, variations in corollary discharge, memory inhibition, and other individual factors. Through this focus, LISN aims to offer a nuanced understanding of the cognitive mechanisms underlying the voice hearing spectrum. Voice Hearing as Predictions Voice hearing has been increasingly studied within the predictive coding framework, which describes perception as a process of hypothesis testing. In this framework, auditory verbal hallucinations (AVH) may arise from an imbalance between top-down predictions and bottom-up sensory input. This fundamental brain mechanism has been explored through various factors, such as neurotransmitter systems, cognitive biases, and socio-emotional factors. This perspective offers a generalised understanding of voice hearing and opens new avenues for prognosis, diagnosis and treatment.\nAt LISN, we focus on experimentally manipulating predictions and sensory input to understand voice hearing better. Methods include conditioning, articulatory suppression, earworm induction, and exposure to different types of auditory noises. We assess the impacts of these manipulations on signal detection task (SDT) performance and self-reported voice hearing experiences (Mak et al., 2023). By demonstrating how voice hearing arises from natural brain processes, we aim to develop methods to characterise voice hearing tendencies across the population. This research helps us understand its prevalence and transition risks to psychosis, while contributing to broader efforts to normalize these experiences and reduce stigma, particularly in underserved communities. Voice Hearing Transition Risks The transition from voice hearing to psychosis is a critical but relatively uncommon area of study in mental health research. While many people experience voice hearing without transitioning to clinical states like psychosis, understanding the factors that contribute to this transition is crucial for early intervention. Research has identified risk factors such as frequency and distress level of voice hearing, comorbid symptoms, and environmental stressors. Neurobiological markers and the concept of a “clinical high-risk state” have also been studied to identify those at increased risk.\nIn collaboration with the Greater Manchester Mental Health NHS Foundation Trust, LISN conducts pioneering research to understand the transition risks among nonclinical voice hearers. Our research focuses on understanding these risks as neurodevelopmental vulnerabilities, which manifest through increasingly complex voice hearing experiences. We also aim to understand the underlying cognitive and neural mechanisms that contribute to this transition. Through this targeted research, LISN seeks to offer insights into the factors that may lead to the transition from voice hearing to psychosis, with the goal of informing early intervention and prevention strategies. Voice Hearing Interventions Interventions for voice hearing have evolved to include a range of approaches, from pharmacological treatments to psychological therapies like CBT and mindfulness. Advanced techniques like …","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577836800,"objectID":"796a36a59dc99fbdcf3464ea717dc976","permalink":"https://lisn-lab.org/research/voicehearing/","publishdate":"2020-01-01T00:00:00Z","relpermalink":"/research/voicehearing/","section":"research","summary":"Voice hearing refers to perceiving non-existent voices. While some people occasionally hear names or imagine familiar voices, others suffer from persistent, distressing voices.  What does this continuum reveal about the brain, and how does occasional voice hearing develop into psychosis?","tags":["Abstract Concepts","Structural Processing","Eye movements","Emotion"],"title":"Voice Hearing","type":"research"},{"authors":["Daisy Watson"],"categories":null,"content":"Close your eyes for a moment and listen. What do you hear? For most of us, beyond any external sounds, there’s that familiar voice inside our head - our inner speech. But have you ever wondered, what if that voice weren’t there at all? Is it possible to have no inner speech?\nMost of us can’t imagine going about our daily lives without ‘the voice inside our head’;\nThis inner voice mediates many of the mechanisms that allow us to perceive the world around us, such as reading and memory. It also encourages us when we need it, keeps our focus when our minds drift and helps us problem-solve and reason. Sometimes, it can even be exploited by our doubts and anxieties to talk us down. The 20th-century, Russian psychologist Lev Vygotsky, in his theory of cognitive development, proposed that we are born social beings. Over time, the conversations we have with those in our surroundings eventually become ‘internalised’, and we discuss our behaviour with ourselves.\nThrough conversations with my peers, I learned just how varied this cognitive tool can be.\nI found that some individuals described their inner speech as largely grammatical, resembling full, structured sentences. Others reported that their inner voices focus exclusively on the semantic meaning, rather than the grammatical features. This type of inner speech is akin to jotting down brief notes that capture only the essential points, also known as condensed inner speech.\nMost people said they use their inner voices to evaluate their own behavior and actions—to criticize or encourage themselves, with varying degrees of each, and one individual even said their mind is focused on this ‘24/7’. This ‘evaluative inner speech’ has been shown to affect our mental states and moods, with some people noting that it helps them feel calmer, while others said it makes them feel more anxious.\nThe complexity of inner speech becomes even more apparent when we consider multilingual individuals. When discussing this topic with a bilingual friend, she shared that, although Hebrew was her first language and the primary language spoken at home, her inner speech has consistently been in English for as long as she can remember. She explained, ‘Even though I didn’t learn it first, it’s the language I’ve grown up around, went to school speaking and it’s the language I’m most comfortable using.’\nThe fascination doesn’t stop there. There’s also a difference in how people experience their inner voices: some say it feels like they’re speaking to themselves, while others feel more like they’re listening to somebody else. Some also report more vivid inner speech when reading, a context in which many describe inner speech that varies in tone, pitch or even accent.\nEvidently, there are a diverse range of uses and forms of inner voice experience. Varying in terms of our perspectives and environments and producing further differences in our moods and mental states.\nThis raises an intriguing question: Is it possible for someone to have no inner speech at all?\nThis area is receiving growing attention, and the answer appears to be yes.\nFor most of us, there is still a line between our inner version of speech, and what researchers call ‘unsymbolised’ concepts – abstract thoughts that aren’t expressed in words. While some report calling upon images instead of words when thinking, others describe experiencing only these unsymbolized thoughts.\nEven when reading, some people who lack inner speech describe comprehension of sentences in ‘concepts’, purely abstract and remote from the written text in front of them. They report understanding meaning directly, without consciously processing the words themselves. Some even describe struggling to think of sentences without saying them verbally.\nThe existence of individuals who lack inner speech has been documented not only with subjective reports but also with objective, behavioural tasks. Researchers coined the term ‘anendophasia’ to describe a lack of inner speech.\nIn a recent study, Nedergaard \u0026amp; Lupyan (2024) examined the differences in cognition between those with inner speech and anendophasics. They gave both groups tasks that typically rely upon inner speech and compared their performance. Their findings were intriguing, recall for verbal working memory, which is closely related to inner speech, was higher for those with inner speech than those without.\nGiven that many individuals consistently report not using, or even not having, inner speech, we can conclude with confidence that the phenomenon of anendophasia is, in fact, a real experience for some people. When results appear to be the same in populations with and without inner speech, this may be because anendophasics have developed alternative cognitive mechanisms to handle behavioral tests.\nThis fascinating dimension of human inner experience creates further interesting questions about the possible consequences of anendophasia on cognition, attention, perception, and mental wellbeing. The …","date":1738281600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1738281600,"objectID":"acb6de964770b1ffa6b754036ca0792d","permalink":"https://lisn-lab.org/post/20250131-anendophasia/","publishdate":"2025-01-31T00:00:00Z","relpermalink":"/post/20250131-anendophasia/","section":"post","summary":"Is it possible to have no inner speech?","tags":["Blog","Anendophasia"],"title":"Inner speechless: Is it possible to have no inner speech?","type":"post"},{"authors":["Madison Hartley"],"categories":null,"content":" Table of Contents What is Aphantasia? Does Aphantasia Affect Everyday Life? The Surprising Benefits of Aphantasia What About You? Contributing to Research Think of an apple in your mind. Can you see a red fruit with a glossy sheen, or… nothing at all? If it is the latter, then you may be part of 2-4% of the world’s population that are aphantasic!\nDon’t worry - aphantasia isn’t a disability or medical condition. It’s simply a different way that the mind processes information and thinks.\nWhat is Aphantasia? Aphantasia is when your brain doesn’t form or use mental images as part of your thinking or imagination. If your mind is like a TV, for someone with Aphantasia, it is as if the screen is blank, with no shapes or colours or… anything at all.\nThis affects even the most familiar objects. For instance, someone I interviewed said they can’t even imagine objects they use every day, such as their phone. They can think about their phone as a concept but literally cannot picture it in their head! Aphantasia can be congenital (from birth) or acquired (developed in later life, often due to illness / injury / mental health condition) and doesn’t need diagnosing. In fact, people often don’t even realise that they are aphantasic, even though they may notice from a young age they lack the ability to form mental images.\nFor example, in a BBC news article Niel Kenmuir said that as a child, he couldn’t fall asleep counting sheep – not because he didn’t want to, but because he simply couldn’t see the sheep in his mind! He didn’t realise this was unusual until adulthood. Indeed, many people didn’t realise until later in life that they were aphantasic, but did notice from a young age that they could not picture things in their mind like others.\nDoes Aphantasia Affect Everyday Life? Aphantasia rarely affects everyday life, as it doesn’t stop them from doing things. However, Aphantasia does impact certain abilities, such as not being able to picture what book characters look like when reading, or finding arts and geometry hard because they can’t manipulate images or shapes in their mind.\nSome Aphantasics experience very poor visual memory – it’d be a struggle for them to recall images from significant events like wedding or their first day at school, and sometimes even to recognise faces.\nThe Surprising Benefits of Aphantasia While having Aphantasia isn’t a limitation – it’s just a different way of thinking. Research suggests it may actually enhance certain cognitive abilities. People with aphantasia often excel in analytical thinking and abstract reasoning, demonstrating superior factual memory and logical problem-solving skills. Additionally, some aphantasic individuals report practical advantages, such as being less affected by traumatic visual memories or disturbing descriptions in books or movies, as they process information conceptually rather than visually.\nWhat About You? Are you curious about how your own mind works? Can you picture an apple? Do you have mental imagery? Have you ever wondered if you might be aphantasic? Understanding your cognitive style can provide valuable insights into how you learn, process information, and interact with the world.\nContributing to Research Your experience matters to the scientific community. As part of our ongoing research into neurodiversity, we’re conducting a study on how aphantasia affects cognition.\nIf you think you are Aphantasic and would like to contribute to our understanding of this fascinating variation in human cognition, please join our research by signing up through the link below.\nYay! Sign Me Up! ","date":1737417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1737417600,"objectID":"369f7baf539433c263b7c3c12fcfad56","permalink":"https://lisn-lab.org/post/20250121-aphantasia/","publishdate":"2025-01-21T00:00:00Z","relpermalink":"/post/20250121-aphantasia/","section":"post","summary":"Are you curious about how your own mind works? Can you picture an apple? Do you have mental imagery?","tags":["Blog","Aphantasia"],"title":"Lack of mental imagery? You may be special!","type":"post"},{"authors":["Bo Yao"],"categories":null,"content":"","date":1736121600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1736121600,"objectID":"8934d139cb8c3deaa6c21fa94a09d0aa","permalink":"https://lisn-lab.org/publication/2025-y-physlife/","publishdate":"2025-01-06T00:00:00Z","relpermalink":"/publication/2025-y-physlife/","section":"publication","summary":"","tags":["inner speech","inner thought","rhythm","neural oscillation"],"title":"It's about time: Rhythmic foundations of inner thought","type":"publication"},{"authors":null,"categories":null,"content":"Our new STARS squad launched their first journal club this week, and it was a hit! Maisie led an engaging discussion on the Variety of Inner Speech Questionnaire-Revised, sparking interesting conversations about inner speech, cultural norms, and individual experiences.\nWe explored how questionnaires like the VISQ can be improved and validated, and potentially be adapted for clinical contexts. We also dipped our toes into the fascinating world of schizophrenia and predictive brain models.\nIt wasn’t all work, though - Summer’s Halloween-themed biscuits added a festive touch to the proceedings. The enthusiasm in the room was palpable, with every member eager to contribute.\nThis successful start sets the stage for an exciting term ahead. Each STAR will have the chance to shine, engaging with a diverse range of topics and lively debates. Stay tuned for more updates!\n","date":1730246400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1730246400,"objectID":"3201a1b971637cb6557ae110b04e5be7","permalink":"https://lisn-lab.org/post/20241030-stars-journalclub/","publishdate":"2024-10-30T00:00:00Z","relpermalink":"/post/20241030-stars-journalclub/","section":"post","summary":"Our new STARS squad launched their first journal club this week, and it was a hit! Maisie led an engaging discussion on the Variety of Inner Speech Questionnaire-Revised, sparking interesting conversations about inner speech, cultural norms, and individual experiences.\n","tags":["News","STARS"],"title":"STARS Squad Kicks Off Journal Club with a Bang!","type":"post"},{"authors":null,"categories":null,"content":"We are thrilled to announce that our lab has been awarded an APEX Award by the Royal Society for an exciting project towards EEG Classification of Auditory Verbal Hallucinations.\nOur research aims to advance the understanding and detection of internal speech experiences akin to auditory verbal hallucinations (AVHs) by combining electroencephalography (EEG) with explainable machine learning. This cross-disciplinary approach brings together experts from neuroscience, psychology, and computer science to develop a potentially game-changing method for monitoring and treating AVHs.\nWe’re excited about the possibilities this project opens up and the potential to improve the lives of those affected by AVHs. Stay tuned for updates as we embark on this exciting new chapter in our research!\n","date":1727740800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1727740800,"objectID":"26ca6018d925c6849957937a5a09c00c","permalink":"https://lisn-lab.org/post/20241001-apex-award/","publishdate":"2024-10-01T00:00:00Z","relpermalink":"/post/20241001-apex-award/","section":"post","summary":"We have been awarded an APEX Award by the Royal Society for an exciting project towards EEG Classification of Auditory Verbal Hallucinations.","tags":["News","Funding"],"title":"Exciting Funding News!","type":"post"},{"authors":["Luiza Mugnol‐Ugarte","Tiago Bortolini","Bo Yao","Mark Mikkelsen","Marina Carneiro Monteiro","Ana Carolina Andorinho de Freitas Ferreira","Ivanei Bramatti","Bruno Melo","Sebastian Hoefle","Fernanda Meireles","Jorge Moll","Gorana Pobric"],"categories":null,"content":"","date":1718841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1718841600,"objectID":"4d05a2169f769d22318f9015c28b3598","permalink":"https://lisn-lab.org/publication/2024-mbmcabmhmmp-scirep/","publishdate":"2024-06-20T00:00:00Z","relpermalink":"/publication/2024-mbmcabmhmmp-scirep/","section":"publication","summary":"Understanding the neural, metabolic, and psychological mechanisms underlying human altruism and decision‐making is a complex and important topic both for science and society. Here, we investigated whether transcranial Direct Current Stimulation (tDCS) applied to two prefrontal cortex regions, the ventromedial prefrontal cortex (vmPFC, anode) and the right dorsolateral prefrontal cortex (DLPFC, cathode) can induce changes in self‐reported emotions and to modulate local metabolite concentrations. We employed in vivo quantitative MR Spectroscopy in healthy adult participants and quantified changes in GABA and Glx (glutamate + glutamine) before and after five sessions of tDCS delivered at 2 mA for 20 min (active group) and 1 min (sham group) while participants were engaged in a charitable donation task. In the active group, we observed increased levels of GABA in vmPFC. Glx levels decreased in both prefrontal regions and self‐reported happiness increased significantly over time in the active group. Self‐reported guiltiness in both active and sham groups tended to decrease. The results indicate that self‐reported happiness can be modulated, possibly due to changes in Glx concentrations following repeated stimulation. Therefore, local changes may induce remote changes in the reward network through interactions with other metabolites, previously thought to be unreachable with noninvasive stimulation techniques.","tags":[],"title":"Transcranial electrical stimulation modulates emotional experience and metabolites in the prefrontal cortex in a donation task","type":"publication"},{"authors":["Bo Yao","Graham G. Scott","Gillian Bruce","Ewa Monteith-Hodge","Sara C. Sereno"],"categories":null,"content":"","date":1717545600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717545600,"objectID":"cae91cc49f4e9b3a9bde24c53cb4270e","permalink":"https://lisn-lab.org/publication/2024-ysbms-cognemo/","publishdate":"2024-06-05T00:00:00Z","relpermalink":"/publication/2024-ysbms-cognemo/","section":"publication","summary":"We replicated and extended the findings of Yao et al. [(2018). Differential emotional processing in concrete and abstract words. Journal of Experimental Psychology: Learning, Memory, and Cognition, 44(7), 1064–1074] regarding the interaction ofemotionality, concreteness, and imageability in word processing by measuring eye fixation times on target words during normal reading. A 3 (Emotion: negative, neutral, positive) × 2 (Concreteness: abstract, concrete) design was used with 22 items per condition, with each set of six target words matched across conditions in terms of word length and frequency. Abstract (e.g. shocking, reserved, fabulous) and concrete (e.g. massacre, calendar, treasure) target words appeared (separately) within contextually neutral, plausible sentences. Sixty-three participants each read all 132 experimental sentences while their eye movements were recorded. Analyses using Gamma generalised linear mixed models revealed significant effects of both Emotion and Concreteness on all fixation measures, indicating faster processing for emotional and concrete words. Additionally, there was a significant Emotion × Concreteness interaction which, critically, was modulated by Imageability in early fixation time measures. Emotion effects were significantly larger in higher-imageability abstract words than in lower-imageability ones, but remained unaffected by imageability in concrete words. These findings support the multimodal induction hypothesis and highlight the intricate interplay of these factors in the immediate stages of word processing during fluent reading.","tags":["emotion","concreteness","word recognition","eye fixations","reading"],"title":"Emotion processing in concrete and abstract words: Evidence from eye fixations during reading","type":"publication"},{"authors":["Jaydan Pratts","Gorana Pobric","Bo Yao"],"categories":null,"content":"","date":1695945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1695945600,"objectID":"5b348567154aee3d0a8b9bb4e775c2e3","permalink":"https://lisn-lab.org/publication/2023-ppy-neuroimage/","publishdate":"2023-09-29T00:00:00Z","relpermalink":"/publication/2023-ppy-neuroimage/","section":"publication","summary":"The neural mechanisms of inner speech remain unclear despite its importance in a variety of cognitive processes and its implication in aberrant perceptions such as auditory verbal hallucinations. Previous research has proposed a corollary discharge model in which inner speech is a truncated form of overt speech, relying on speech production-related regions (e.g. left inferior frontal gyrus). This model does not fully capture the diverse phenomenology of inner speech and recent research suggesting alternative perception-related mechanisms of generation. Therefore, we present and test a framework in which inner speech can be generated by two separate mechanisms, depending on its phenomenological qualities: a corollary discharge mechanism relying on speech production regions and a perceptual simulation mechanism within speech perceptual regions. The results of the activation likelihood estimation meta-analysis examining inner speech studies support the idea that varieties of inner speech recruit different neural mechanisms.","tags":["inner speech","corollary discharge","perceptual simulation","meta-analysis","GingerALE"],"title":"Bridging phenomenology and neural mechanisms of inner speech: ALE meta-analysis on egocentricity and spontaneity in a dual-mechanistic framework","type":"publication"},{"authors":["Olivia Mak","Samuel Couth","Christopher J. Plack","Sonja A. Kotz","Bo Yao"],"categories":null,"content":"","date":1688601600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688601600,"objectID":"376a684940feb75ca1dfaa136ac92dc9","permalink":"https://lisn-lab.org/publication/2023-mcpky-fin/","publishdate":"2023-07-06T00:00:00Z","relpermalink":"/publication/2023-mcpky-fin/","section":"publication","summary":"**Introduction:** Auditory verbal hallucinations (AVHs), or hearing non-existent voices, are a common symptom in psychosis. Recent research suggests that AVHs are also experienced by neurotypical individuals. Individuals with schizophrenia experiencing AVHs and neurotypicals who are highly prone to hallucinate both produce false positive responses in auditory signal detection. These findings suggest that voice-hearing may lie on a continuum with similar mechanisms underlying AVHs in both populations. **Methods:** The current study used a monaural auditory stimulus in a signal detection task to test to what extent experimentally induced verbal hallucinations are (1) left- lateralised (i.e., more likely to occur when presented to the right ear compared to the left ear due to the left-hemisphere dominance for language processing), and (2) predicted by self-reported hallucination proneness and auditory imagery tendencies. In a conditioning task, fifty neurotypical participants associated a negative word on-screen with the same word being played via headphones through successive simultaneous audio-visual presentations. A signal detection task followed where participants were presented with a target word on-screen and indicated whether they heard the word being played concurrently amongst white noise. **Results:** Results showed that Pavlovian audio-visual conditioning reliably elicited a significant number of false positives (FPs). However, FP rates, perceptual sensitivities, and response biases did not differ between either ear. They were neither predicted by hallucination proneness nor auditory imagery. **Discussion:** The results show that experimentally induced FPs in neurotypicals are not left-lateralised, adding further weight to the argument that lateralisation may not be a defining feature of hallucinations in clinical or non-clinical populations. The findings also support the idea that AVHs may be a continuous phenomenon that varies in severity and frequency across the population. Studying induced AVHs in neurotypicals may help identify the underlying cognitive and neural mechanisms contributing to AVHs in individuals with psychotic disorders.","tags":["auditory verbal hallucination (AHV)","signal detection","lateralisation","hearing voices","Pavlovian conditioning","neurotypical populations"],"title":"Investigating the lateralisation of experimentally induced auditory verbal hallucinations","type":"publication"},{"authors":["Bo Yao","Jack E. Taylor","Sara C. Sereno"],"categories":null,"content":"","date":1669852800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669852800,"objectID":"e717350af3f3e91d7469ef8d8c38d483","permalink":"https://lisn-lab.org/publication/2022-yts-jml/","publishdate":"2022-12-01T00:00:00Z","relpermalink":"/publication/2022-yts-jml/","section":"publication","summary":"Embodied cognition theories propose that abstract concepts are grounded in a variety of exogenous and endogenous experiences which may be flexibly activated across contexts and tasks. In three experiments, we explored how semantic size (i.e., the magnitude, dimension or extent of an object or a concept) of abstract (vs concrete) concepts is mentally represented. We show that abstract size is metaphorically associated with the physical size of concrete objects (Experiment 1) and can produce a semantic-font size congruency effect comparable to that demonstrated in concrete words during online lexical processing (Experiment 2). Critically, this size congruency effect is large when a word is judged by its semantic size but significantly smaller when it is judged by its emotionality (Experiment 3), regardless of concreteness. Our results suggest that semantic size of abstract concepts can be grounded in visual size, which is activated adaptively under different task demands. The present findings advocate flexible embodiment of semantic representations, with an emphasis on the role of task effects on conceptual processing.","tags":["abstract concepts","semantic size","embodied cognition","emotion","metaphor"],"title":"What can size tell us about abstract conceptual processing?","type":"publication"},{"authors":null,"categories":null,"content":"","date":1666569600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666569600,"objectID":"c1d17ff2b20dca0ad6653a3161942b64","permalink":"https://lisn-lab.org/people/","publishdate":"2022-10-24T00:00:00Z","relpermalink":"/people/","section":"","summary":"","tags":null,"title":"People","type":"landing"},{"authors":["Bo Yao","Jason R. Taylor","Briony Banks","Sonja A. Kotz"],"categories":null,"content":"","date":1633046400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633046400,"objectID":"60bcc8fd808fc22a64c9a0898f940ade","permalink":"https://lisn-lab.org/publication/2021-ytbk-neuroimage/","publishdate":"2021-10-01T00:00:00Z","relpermalink":"/publication/2021-ytbk-neuroimage/","section":"publication","summary":"Growing evidence shows that theta-band (4–7 Hz) activity in the auditory cortex phase-locks to rhythms of overt speech. Does theta activity also encode the rhythmic dynamics of inner speech? Previous research established that silent reading of direct speech quotes (e.g., _Mary said: “This dress is lovely!”_) elicits more vivid inner speech than indirect speech quotes (e.g., _Mary said that the dress was lovely_). As we cannot directly track the phase alignment between theta activity and inner speech over time, we used EEG to measure the brain's phase-locked responses to the onset of speech quote reading. We found that direct (vs. indirect) quote reading was associated with increased theta phase synchrony over trials at 250–500 ms post-reading onset, with sources of the evoked activity estimated in the speech processing network. An eye-tracking control experiment confirmed that increased theta phase synchrony in direct quote reading was not driven by eye movement patterns, and more likely reflects synchronous phase resetting at the onset of inner speech. These findings suggest a functional role of theta phase modulation in reading-induced inner speech.","tags":["inner speech","neural oscillations","phase synchrony","phase-locking","silent reading","theta oscillations","EEG","eye tracking"],"title":"Reading direct speech quotes increases theta phase-locking: Evidence for cortical tracking of inner speech?","type":"publication"},{"authors":["Bo Yao"],"categories":null,"content":"","date":1610064000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1610064000,"objectID":"5f58312758838b5b55f52d02eca5ce07","permalink":"https://lisn-lab.org/publication/2021-y-jocognition/","publishdate":"2021-01-08T00:00:00Z","relpermalink":"/publication/2021-y-jocognition/","section":"publication","summary":"Embodied theories propose that language is understood via mental simulations of sensory states related to perception and action. Given that direct speech (e.g., _She says, “It’s a lovely day!”_) is perceived to be more vivid than indirect speech (e.g., _She says (that) it’s a lovely day_) in perception, recent research shows in silent reading that more vivid speech representations are mentally simulated for direct speech than for indirect speech. This ‘simulated’ speech is found to contain suprasegmental prosodic representations (e.g., speech prosody) but its phonological detail and its causal role in silent reading of direct speech remain unclear. Here in three experiments, I explored the phonological aspect and the causal role of speech simulations in silent reading of tongue twisters in direct speech, indirect speech and non-speech sentences. The results demonstrated greater visual tongue-twister effects (phonemic interference) during silent reading (Experiment 1) but not oral reading (Experiment 2) of direct speech as compared to indirect speech and non-speech. The tongue-twister effects in silent reading of direct speech were selectively disrupted by phonological interference (concurrent articulation) as compared to manual interference (finger tapping) (Experiment 3). The results replicated more vivid speech simulations in silent reading of direct speech, and additionally extended them to the phonological dimension. Crucially, they demonstrated a causal role of phonological simulations in silent reading of direct speech, at least in tongue-twister reading. The findings are discussed in relation to multidimensionality and task dependence of mental simulation and its mechanisms.","tags":["inner speech","tongue twisters","phonemic interference","eye tracking","silent reading","speech quotations","embodied cognition","articulatory suppression"],"title":"Mental simulations of phonological representations are causally linked to silent reading of direct versus indirect speech","type":"publication"},{"authors":["Ben Alderson-Day","Jamie Moffatt","Marco Bernini","Kaja Mitrenga","Bo Yao","Charles Fernyhough"],"categories":null,"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"b1768e92e360696878ac5fa3324db7d7","permalink":"https://lisn-lab.org/publication/2020-ambmyf-jocn/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/publication/2020-ambmyf-jocn/","section":"publication","summary":"Stories transport readers into vivid imaginative worlds, but understanding how readers create such worlds—populating them with characters, objects, and events—presents serious challenges across disciplines. Auditory imagery is thought to play a prominent role in this process, especially when representing characters' voices. Previous research has shown that direct reference to speech in stories (e.g., _He said, “I'm over here”_) may prompt spontaneous activation of voice-selective auditory cortex more than indirect speech [Yao, B., Belin, P., \u0026 Scheepers, C. Silent reading of direct versus indirect speech activates voice-selective areas in the auditory cortex. Journal of Cognitive Neuroscience, 23, 3146–3152, 2011]. However, it is unclear whether this effect reflects differential processing of speech or differences in linguistic content, source memory, or grammar. One way to test this is to compare direct reference effects for characters speaking and thinking in a story. Here, we present a multidisciplinary fMRI study of 21 readers' responses to characters' speech and thoughts during silent reading of short fictional stories. Activations relating to direct and indirect references were compared for both speaking and thinking. Eye-tracking and independent localizer tasks (auditory cortex and theory of mind [ToM]) established ROIs in which responses to stories could be tracked for individuals. Evidence of elevated auditory cortex responses to direct speech over indirect speech was observed, replicating previously reported effects; no reference effect was observed for thoughts. Moreover, a direct reference effect specific to speech was also evident in regions previously associated with inferring intentions from communication. Implications are discussed for the spontaneous representation of fictional characters and the potential roles of inner speech and ToM in this process.","tags":["inner speech","fMRI","eye tracking","speech quotations","thoughts","silent reading","Theory of Mind"],"title":"Processing speech and thoughts during silent reading: Direct reference effects for speech by fictional characters in voice-selective auditory cortex and a Theory-of-Mind network","type":"publication"},{"authors":["Graham G. Scott","Anne Keitel","Marc Becirspahic","Bo Yao","Sara C. Sereno"],"categories":null,"content":"","date":1559347200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559347200,"objectID":"c7dfeadbd34de06bbc2f4abfdbbe9c08","permalink":"https://lisn-lab.org/publication/2019-skbys-brm/","publishdate":"2019-06-01T00:00:00Z","relpermalink":"/publication/2019-skbys-brm/","section":"publication","summary":"The Glasgow Norms are a set of normative ratings for 5,553 English words on nine psycholinguistic dimensions: arousal, valence, dominance, concreteness, imageability, familiarity, age of acquisition, semantic size, and gender association. The Glasgow Norms are unique in several respects. First, the corpus itself is relatively large, while simultaneously providing norms across a substantial number of lexical dimensions. Second, for any given subset of words, the same participants provided ratings across all nine dimensions (33 participants/word, on average). Third, two novel dimensions—semantic size and gender association—are included. Finally, the corpus contains a set of 379 ambiguous words that are presented either alone (e.g., toast) or with information that selects an alternative sense (e.g., toast (bread), toast (speech)). The relationships between the dimensions of the Glasgow Norms were initially investigated by assessing their correlations. In addition, a principal component analysis revealed four main factors, accounting for 82% of the variance (Visualization, Emotion, Salience, and Exposure). The validity of the Glasgow Norms was established via comparisons of our ratings to 18 different sets of current psycholinguistic norms. The dimension of size was tested with megastudy data, confirming findings from past studies that have explicitly examined this variable. Alternative senses of ambiguous words (i.e., disambiguated forms), when discordant on a given dimension, seemingly led to appropriately distinct ratings. Informal comparisons between the ratings of ambiguous words and of their alternative senses showed different patterns that likely depended on several factors (the number of senses, their relative strengths, and the rating scales themselves). Overall, the Glasgow Norms provide a valuable resource—in particular, for researchers investigating the role of word recognition in language comprehension.","tags":["psycholinguistic norms","arousal","valence","dominance","concreteness","imageability","familiarity","age of acquisition","semantic size","gender association"],"title":"The Glasgow Norms: Ratings of 5,500 words on nine scales","type":"publication"},{"authors":["Bo Yao","Christoph Scheepers"],"categories":null,"content":"","date":1531612800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1531612800,"objectID":"2f391990e9f0678304dcd8035c72b15f","permalink":"https://lisn-lab.org/publication/2018-ys-cognition/","publishdate":"2018-07-15T00:00:00Z","relpermalink":"/publication/2018-ys-cognition/","section":"publication","summary":"The implicit prosody hypothesis (Fodor, 1998, 2002) proposes that silent reading coincides with a default, implicit form of prosody to facilitate sentence processing. Recent research demonstrated that a more vivid form of implicit prosody is mentally simulated during silent reading of direct speech quotations (e.g., _Mary said, “This dress is beautiful”_), with neural and behavioural consequences (e.g., Yao, Belin, \u0026 Scheepers, 2011; Yao \u0026 Scheepers, 2011). Here, we explored the relation between ‘default’ and ‘simulated’ implicit prosody in the context of relative-clause (RC) attachment in English. Apart from conﬁrming a general low RC-attachment preference in both production (Experiment 1) and comprehension (Experiments 2 and 3), we found that during written sentence completion (Experiment 1) or when reading silently (Experiment 2), the low RC-attachment preference was reliably enhanced when the critical sentences were embedded in direct speech quotations as compared to indirect speech or narrative sentences. However, when reading aloud (Experiment 3), direct speech did not enhance the general low RC-attachment preference. The results from Experiments 1 and 2 suggest a quantitative boost to implicit prosody (via auditory perceptual simulation) during silent production/comprehension of direct speech. By contrast, when reading aloud (Experiment 3), prosody becomes equally salient across conditions due to its explicit nature; indirect speech and narrative sentences thus become as susceptible to prosody-induced syntactic biases as direct speech. The present ﬁndings suggest a shared cognitive basis between default implicit prosody and simulated implicit prosody, providing a new platform for studying the eﬀects of implicit prosody on sentence processing.","tags":["inner speech","implicit prosody","relative-clause attachment","speech quotations","mental simulation"],"title":"Direct speech quotations promote low relative-clause attachment in silent reading of English","type":"publication"},{"authors":["Andrew J. Stewart","Jeffrey S. Wood","Elizabeth Le-Luan","Bo Yao","Matthew Haigh"],"categories":null,"content":"","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"9095462d1d44700c44b3f697b9776122","permalink":"https://lisn-lab.org/publication/2018-swlyh-qjep/","publishdate":"2018-06-01T00:00:00Z","relpermalink":"/publication/2018-swlyh-qjep/","section":"publication","summary":"In an eye-tracking experiment, we examined how readers comprehend indirect replies when they are uttered in reply to a direct question. Participants read vignettes that described two characters engaged in dialogue. Each dialogue contained a direct question (e.g., How are you doing in Chemistry?) answered with an excuse (e.g., The exams are not fair). In response to direct questions, such indirect replies are typically used to avoid a face-threatening disclosure (e.g., doing badly on the Chemistry course). Our goal was to determine whether readers are sensitive during reading to the indirect meaning communicated by such replies. Of the three contexts we examined, the first described a negative, face-threatening situation and the second a positive, non-face threatening situation, while the third was neutral. Analysis of reading times to the replies provides strong evidence that readers are sensitive online to the face-saving function of indirect replies.","tags":["face management","indirect meaning","indirect replies","discourse processing"],"title":"‘It’s hard to write a good article’: The online comprehension of excuses as indirect replies","type":"publication"},{"authors":["Andrew J. Stewart","Elizabeth Le-Luan","Jeffrey S. Wood","Bo Yao","Matthew Haigh"],"categories":null,"content":"","date":1518825600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518825600,"objectID":"06d78b439a6ee1d26dbadf8fc7d87dbc","permalink":"https://lisn-lab.org/publication/2018-slwyh-discourseprocesses/","publishdate":"2018-02-17T00:00:00Z","relpermalink":"/publication/2018-slwyh-discourseprocesses/","section":"publication","summary":"In everyday conversation much communication is achieved using indirect language. This is particularly true when we utter requests. The decision to use indirect language is influenced by a number of factors, including deniability, politeness, and the degree of imposition on the receiver of a request. In this article we report the results of an eye-tracking experiment examining the influence on reading of the degree of imposition of a request. We manipulate whether context describes a situation in which the level of imposition on the receiver of the request is high (which thus motivates the use of indirect language) with one in which the level of imposition is low (and thus does not motivate the use of indirect language). We compare the comprehension of statements that are phrased indirectly with the comprehension of statements that are phrased more directly. We find that statements phrased indirectly are read more quickly in contexts where the level of imposition on the receiver is high versus when the level of imposition is low. In contrast, we find the processing of statements phrased directly does not vary as a function of level of imposition. This indicates that readers use pragmatic knowledge to guide interpretation of indirect requests. Our data provide an insight into the interface between pragmatic and semantic processing.","tags":["pragmatics","indirect requests","communication","discourse processing"],"title":"Comprehension of indirect requests is influenced by their degree of imposition","type":"publication"},{"authors":["Bo Yao","Anne Keitel","Gillian Bruce","Graham G. Scott","Patrick J. O'Donnell","Sara C. Sereno"],"categories":null,"content":"","date":1518393600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1518393600,"objectID":"e43947d0f686c721d3e0d51b5603ed68","permalink":"https://lisn-lab.org/publication/2018-ykbsos-jeplmc/","publishdate":"2018-02-12T00:00:00Z","relpermalink":"/publication/2018-ykbsos-jeplmc/","section":"publication","summary":"Emotion (positive and negative) words are typically recognized faster than neutral words. Recent research suggests that emotional valence, while often treated as a unitary semantic property, may be differentially represented in concrete and abstract words. Studies that have explicitly examined the interaction of emotion and concreteness, however, have demonstrated inconsistent patterns of results. Moreover, these findings may be limited as certain key lexical variables (e.g., familiarity, age of acquisition) were not taken into account. We investigated the emotion-concreteness interaction in a large-scale, highly controlled lexical decision experiment. A 3 (Emotion: negative, neutral, positive) × 2 (Concreteness: abstract, concrete) design was used, with 45 items per condition and 127 participants. We found a significant interaction between emotion and concreteness. Although positive and negative valenced words were recognized faster than neutral words, this emotion advantage was significantly larger in concrete than in abstract words. We explored potential contributions of participant alexithymia level and item imageability to this interactive pattern. We found that only word imageability significantly modulated the emotion-concreteness interaction. While both concrete and abstract emotion words are advantageously processed relative to comparable neutral words, the mechanisms of this facilitation are paradoxically more dependent on imageability in abstract words.","tags":["emotion","concreteness","embodied cognition","alexithymia","imageability"],"title":"Differential emotional processing in concrete and abstract words","type":"publication"},{"authors":["Sara C. Sereno","Christopher J. Hand","Aisha Shahid","Bo Yao","Patrick J. O'Donnell"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"22141f8672af8f64d96870e0ea1dbcd9","permalink":"https://lisn-lab.org/publication/2018-shsyo-qjep/","publishdate":"2018-01-01T00:00:00Z","relpermalink":"/publication/2018-shsyo-qjep/","section":"publication","summary":"Contextual constraint is a key factor affecting a word’s fixation duration and its likelihood of being fixated during reading. Previous research has generally demonstrated additive effects of predictability and frequency in fixation times. Studies examining the role of parafoveal preview have shown that greater preview benefit is obtained from more predictable and higher frequency words versus less predictable and lower frequency words. In two experiments, we investigated effects of target word predictability, frequency and parafoveal preview. A 3 (Predictability: low, medium, high) × 2 (Frequency: low, high) design was used with Preview (valid, invalid) manipulated between experiments. With valid previews, we found main effects of Predictability and Frequency in both fixation time and fixation probability measures, including an interaction in early fixation measures. With invalid preview, we again found main effects of Predictability and Frequency in fixation times, but no evidence of an interaction. Fixation probability showed a weak Predictability effect and Predictability–Frequency interaction. Predictability interacted with Preview in early fixation time and fixation probability measures. Our findings suggest that high levels of contextual constraint exert an early influence during lexical processing in reading. Results are discussed in terms of models of language processing and eye movement control.","tags":["contextual predictability","word frequency","parafoveal preview","eye tracking","silent reading"],"title":"Testing the limits of contextual constraint: Interactions with word frequency and parafoveal preview during fluent reading","type":"publication"},{"authors":["Mario Weick","John A. Allen","Milica Vasiljevic","Bo Yao"],"categories":null,"content":"","date":1454284800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1454284800,"objectID":"c67a4bea849bd72e344ddd7afb4305a2","permalink":"https://lisn-lab.org/publication/2016-wavy-cognition/","publishdate":"2016-02-01T00:00:00Z","relpermalink":"/publication/2016-wavy-cognition/","section":"publication","summary":"Healthy individuals display a tendency to allocate attention unequally across space, and this bias has implications for how individuals interact with their environments. However, the origins of this phenomenon remain relatively poorly understood. The present research examined the joint and independent contributions of two fundamental motivational systems – behavioural approach and inhibition systems (BAS and BIS) – to lateral spatial bias in a locomotion task. Participants completed self-report measures of trait BAS and BIS, then repeatedly traversed a room, blindfolded, aiming for a straight line. We obtained locomotion data from motion tracking to capture variations in the walking trajectories. Overall, walking trajectories deviated to the left, and this tendency was more pronounced with increasing BIS scores. Meanwhile, BAS was associated with relative rightward tendencies when BIS was low, but not when BIS was high. These results demonstrate for the first time an association between BIS and lateral spatial bias independently of variations in BAS. The findings also contribute to clarify the circumstances in which BAS is associated with a rightward bias. We discuss the implications of these findings for the neurobiological underpinnings of BIS and for the literature on spatial bias.","tags":["spatial bias","lateralisation","motion tracking"],"title":"Walking blindfolded unveils unique contributions of behavioural approach and inhibition to lateral spatial bias","type":"publication"},{"authors":["Sara C. Sereno","Graham G. Scott","Bo Yao","Elske J. Thaden","Patrick J. O'Donnell"],"categories":null,"content":"","date":1440374400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1440374400,"objectID":"0db14ba45d7b086a696c17eaafeac461","permalink":"https://lisn-lab.org/publication/2015-ssyto-frontierpsych/","publishdate":"2015-08-24T00:00:00Z","relpermalink":"/publication/2015-ssyto-frontierpsych/","section":"publication","summary":"Visual emotion word processing has been in the focus of recent psycholinguistic research. In general, emotion words provoke differential responses in comparison to neutral words. However, words are typically processed within a context rather than in isolation. For instance, how does one's inner emotional state influence the comprehension of emotion words? To address this question, the current study examined lexical decision responses to emotionally positive, negative, and neutral words as a function of induced mood as well as their word frequency. Mood was manipulated by exposing participants to different types of music. Participants were randomly assigned to one of three conditions—no music, positive music, and negative music. Participants' moods were assessed during the experiment to confirm the mood induction manipulation. Reaction time results confirmed prior demonstrations of an interaction between a word's emotionality and its frequency. Results also showed a significant interaction between participant mood and word emotionality. However, the pattern of results was not consistent with mood-congruency effects. Although positive and negative mood facilitated responses overall in comparison to the control group, neither positive nor negative mood appeared to additionally facilitate responses to mood-congruent words. Instead, the pattern of findings seemed to be the consequence of attentional effects arising from induced mood. Positive mood broadens attention to a global level, eliminating the category distinction of positive-negative valence but leaving the high-low arousal dimension intact. In contrast, negative mood narrows attention to a local level, enhancing within-category distinctions, in particular, for negative words, resulting in less effective facilitation.","tags":["emotion","mood induction","valence","arousal","word frequency","visual word recognition","lexcial decision"],"title":"Emotion word processing: Does mood make a difference?","type":"publication"},{"authors":["Bo Yao","Christoph Scheepers"],"categories":null,"content":"","date":1435104000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1435104000,"objectID":"1657ba3c8c376573a0aab7dcb20b1510","permalink":"https://lisn-lab.org/publication/2015-ys-eaipisp/","publishdate":"2015-06-24T00:00:00Z","relpermalink":"/publication/2015-ys-eaipisp/","section":"publication","summary":"In this chapter, we review recent research concerned with “inner voice” experiences during silent reading of direct speech (e.g., _Mary said, “This dress is beautiful!”_) and indirect speech (e.g., _Mary said that the dress was beautiful_). Converging findings from speech analysis, brain imaging, and eye tracking indicate that readers spontaneously engage in mental simulations of audible-speech like representations during silent reading of direct speech, and to a much lesser extent during silent reading of indirect speech. This “simulated” implicit prosody is highly correlated with the overt prosody generated during actual speaking. We then compare this “simulated” implicit prosody with the sort of “default” implicit prosody that is commonly discussed in relation to syntactic ambiguity resolution. We hope our discussion will motivate new interdisciplinary research into prosodic processing during reading which could potentially unify the two phenomena within a single theoretical framework.","tags":["inner speech","implicit prosody","silent reading","fMRI","eye tracking"],"title":"Inner voice experiences during processing of direct and indirect speech","type":"publication"},{"authors":["Bo Yao","Graham G. Scott","Phil McAleer","Patrick J. O'Donnell","Sara C. Sereno"],"categories":null,"content":"","date":1407888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1407888000,"objectID":"8ce4ca398233a1cdecc962a3f68daed8","permalink":"https://lisn-lab.org/publication/2014-ysmos-plosone/","publishdate":"2014-08-13T00:00:00Z","relpermalink":"/publication/2014-ysmos-plosone/","section":"publication","summary":"Although gossip serves several important social functions, it has relatively infrequently been the topic of systematic investigation. In two experiments, we advance a cognitive-informational approach to gossip. Specifically, we sought to determine which informational components engender gossip. In Experiment 1, participants read brief passages about other people and indicated their likelihood to share this information. We manipulated target familiarity (celebrity, non-celebrity) and story interest (interesting, boring). While participants were more likely to gossip about celebrity than non-celebrity targets and interesting than boring stories, they were even more likely to gossip about celebrity targets embedded within interesting stories. In Experiment 2, we additionally probed participants' reactions to the stories concerning emotion, expectation, and reputation information conveyed. Analyses showed that while such information partially mediated target familiarity and story interest effects, only expectation and reputation accounted for the interactive pattern of gossip behavior. Our findings provide novel insights into the essential components and processing mechanisms of gossip.","tags":["gossip","moderated mediation analysis","expectation","emotion"],"title":"Familiarity with interest breeds gossip: Contributions of emotion, expectation, and reputation","type":"publication"},{"authors":["Bo Yao","Milica Vasiljevic","Mario Weick","Margaret E. Sereno","Patrick J. O'Donnell","Sara C. Sereno"],"categories":null,"content":"","date":1380067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1380067200,"objectID":"f130d3013c0950a2dfe529ef15393d7c","permalink":"https://lisn-lab.org/publication/2013-yvwsos-plosone/","publishdate":"2013-09-25T00:00:00Z","relpermalink":"/publication/2013-yvwsos-plosone/","section":"publication","summary":"Size is an important visuo-spatial characteristic of the physical world. In language processing, previous research has demonstrated a processing advantage for words denoting semantically “big” (e.g., *jungle* versus “small” (e.g., *needle*) concrete objects. We investigated whether semantic size plays a role in the recognition of words expressing abstract concepts (e.g., *truth*). Semantically “big” and “small” concrete and abstract words were presented in a lexical decision task. Responses to “big” words, regardless of their concreteness, were faster than those to “small” words. Critically, we explored the relationship between semantic size and affective characteristics of words as well as their influence on lexical access. Although a word’s semantic size was correlated with its emotional arousal, the temporal locus of arousal effects may depend on the level of concreteness. That is, arousal seemed to have an earlier (lexical) effect on abstract words, but a later (post-lexical) effect on concrete words. Our findings provide novel insights into the semantic representations of size in abstract concepts and highlight that affective attributes of words may not always index lexical access.","tags":["abstract concepts","semantic size","lexical decision","embodied cognition","emotion"],"title":"Semantic size of abstract concepts: It gets emotional when you can’t see it","type":"publication"},{"authors":["Bo Yao","Pascal Belin","Christoph Scheepers"],"categories":null,"content":"","date":1334448000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1334448000,"objectID":"6ce408e234d1952eaecb21e92063c33f","permalink":"https://lisn-lab.org/publication/2012-ybs-neuroimage/","publishdate":"2012-04-15T00:00:00Z","relpermalink":"/publication/2012-ybs-neuroimage/","section":"publication","summary":"In human communication, direct speech (e.g., _Mary said, “I'm hungry”_) is perceived as more vivid than indirect speech (e.g., _Mary said that she was hungry_). This vividness distinction has previously been found to underlie silent reading of quotations: Using functional magnetic resonance imaging (fMRI), we found that direct speech elicited higher brain activity in the temporal voice areas (TVA) of the auditory cortex than indirect speech, consistent with an “inner voice” experience in reading direct speech. Here we show that listening to monotonously spoken direct versus indirect speech quotations also engenders differential TVA activity. This suggests that individuals engage in top-down simulations or imagery of enriched supra-segmental acoustic representations while listening to monotonous direct speech. The findings shed new light on the acoustic nature of the “inner voice” in understanding direct speech.","tags":["speech perception","fMRI","mental simulation","embodied cognition","emotional prosody"],"title":"Brain ‘talks over’ boring quotes: Top-down activation of voice-selective areas while listening to monotonous direct speech quotations","type":"publication"},{"authors":["Bo Yao","Christoph Scheepers"],"categories":null,"content":"","date":1322697600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1322697600,"objectID":"f30394a245cd0d6626f2c5d74c7304b1","permalink":"https://lisn-lab.org/publication/2011-ys-cognition/","publishdate":"2011-12-01T00:00:00Z","relpermalink":"/publication/2011-ys-cognition/","section":"publication","summary":"In human communication, direct speech (e.g., *Mary said, “I’m hungry”*) is perceived to be more vivid than indirect speech (e.g., *Mary said [that] she was hungry*). However, the processing consequences of this distinction are largely unclear. In two experiments, participants were asked to either orally (Experiment 1) or silently (Experiment 2, eye-tracking) read written stories that contained either a direct speech or an indirect speech quotation. The context preceding those quotations described a situation that implied either a fast-speaking or a slow-speaking quoted protagonist. It was found that this context manipulation affected reading rates (in both oral and silent reading) for direct speech quotations, but not for indirect speech quotations. This suggests that readers are more likely to engage in perceptual simulations of the reported speech act when reading direct speech as opposed to meaning-equivalent indirect speech quotations, as part of a more vivid representation of the former.","tags":["inner speech","silent reading","eye tracking","mental simulation","embodied cognition"],"title":"Contextual modulation of reading rate for direct versus indirect speech quotations","type":"publication"},{"authors":["Bo Yao","Pascal Belin","Christoph Scheepers"],"categories":null,"content":"","date":1317427200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1317427200,"objectID":"9e625fdf956472c99a5cb618cc5a82b5","permalink":"https://lisn-lab.org/publication/2011-ybs-jocn/","publishdate":"2011-10-01T00:00:00Z","relpermalink":"/publication/2011-ybs-jocn/","section":"publication","summary":"In human communication, direct speech (e.g., _Mary said, “I'm hungry”_) is perceived to be more vivid than indirect speech (e.g., _Mary said [that] she was hungry_). However, for silent reading, the representational consequences of this distinction are still unclear. Although many of us share the intuition of an “inner voice,” particularly during silent reading of direct speech statements in text, there has been little direct empirical confirmation of this experience so far. Combining fMRI with eye tracking in human volunteers, we show that silent reading of direct versus indirect speech engenders differential brain activation in voice-selective areas of the auditory cortex. This suggests that readers are indeed more likely to engage in perceptual simulations (or spontaneous imagery) of the reported speaker's voice when reading direct speech as opposed to meaning-equivalent indirect speech statements as part of a more vivid representation of the former. Our results may be interpreted in line with embodied cognition and form a starting point for more sophisticated interdisciplinary research on the nature of auditory mental simulation during reading.","tags":["inner speech","silent reading","fMRI","eye tracking","mental simulation","embodied cognition"],"title":"Silent reading of direct versus indirect speech activates voice-selective areas in the auditory cortex","type":"publication"}]