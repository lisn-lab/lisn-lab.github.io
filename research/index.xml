<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Research Foci | LISN Lab</title>
    <link>http://localhost:1313/research/</link>
      <atom:link href="http://localhost:1313/research/index.xml" rel="self" type="application/rss+xml" />
    <description>Research Foci</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 01 Jan 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu12750140480456391776.png</url>
      <title>Research Foci</title>
      <link>http://localhost:1313/research/</link>
    </image>
    
    <item>
      <title>Language</title>
      <link>http://localhost:1313/research/language/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/research/language/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#abstract-concepts&#34;&gt;Abstract Concepts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#structural-processing&#34;&gt;Structural Processing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#eye-movements-in-reading&#34;&gt;Eye Movements in Reading&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#language-and-emotion&#34;&gt;Language and Emotion&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;abstract-concepts&#34;&gt;Abstract Concepts&lt;/h2&gt;
&lt;p&gt;Abstract concepts like &amp;ldquo;love&amp;rdquo; or &amp;ldquo;trust&amp;rdquo; pose a unique challenge in cognitive science. Unlike concrete concepts such as &amp;ldquo;red,&amp;rdquo; which derive meaning from direct sensory experiences, abstract concepts lack physical referents. This absence raises questions about how such concepts are represented in the mind and complicates the prevailing &amp;rsquo;embodied&amp;rsquo; theory of concept representation, which suggests that concepts gain meaning through bodily experiences.&lt;/p&gt;
&lt;p&gt;At LISN, we tackle these challenges by exploring alternative grounding for abstract concepts. We investigate whether emotional or metaphorical experiences provide the basis for understanding abstract words. For example, &amp;rsquo;trust&amp;rsquo; is often considered a &amp;lsquo;big&amp;rsquo; concept because it elicits strong emotions &lt;a href=&#34;http://localhost:1313/publication/2013-YVWSOS-PlosONE&#34;&gt;(Yao et al., 2013)&lt;/a&gt; and is metaphorically associated with large objects like &amp;lsquo;castle&amp;rsquo; or &amp;lsquo;cathedral&amp;rsquo; &lt;a href=&#34;http://localhost:1313/publication/2022-YTS-JML&#34;&gt;(Yao, Taylor, &amp;amp; Sereno, 2022)&lt;/a&gt;. Our research also examines the possibility that abstract concepts have a more episodic and context-dependent grounding compared to concrete ones. For instance, the concept of &amp;rsquo;love&amp;rsquo; can vary significantly depending on the context, such as a romantic dinner or a care home, unlike more concrete concepts like &amp;lsquo;cat,&amp;rsquo; which consistently evoke features like fur and paws. We extend this inquiry to understand how embodied experiences influence language comprehension across various contexts and life stages.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;structural-processing&#34;&gt;Structural Processing&lt;/h2&gt;
&lt;p&gt;Structural processing in language is a complex cognitive function that extends beyond mere syntax. It involves breaking down sentences into components such as subjects, verbs, and objects, and understanding their interrelationships to extract meaning. This function also intersects with other cognitive domains like prosody - the intonation in spoken sentences - and arithmetic operations, highlighting its role as a domain-general mechanism crucial for structuring language, cognition, and communication.&lt;/p&gt;
&lt;p&gt;At LISN, our focus is twofold. First, we explore the link between implicit prosody in reading, commonly known as &amp;ldquo;inner speech,&amp;rdquo; and syntactic processing. This helps us understand how the &amp;lsquo;melody&amp;rsquo; of language in our minds influences sentence interpretation &lt;a href=&#34;http://localhost:1313/publication/2018-YS-Cognition&#34;&gt;(Yao &amp;amp; Scheepers, 2018)&lt;/a&gt;. Second, we study how sentence structures in different languages affect cognition among their speakers. For example, Chinese sentences often omit subjects and focus on topics, whereas English sentences require subjects and emphasise them. This difference could lead to varying attentional focuses and mental representations. We also examine the contrasting structures between left-branching languages like Chinese and right-branching languages like English, suggesting different structural hierarchies between languages. Through these investigations, we aim to untangle the complexities of structural processing and its influence on cognition and communication.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;eye-movements-in-reading&#34;&gt;Eye Movements in Reading&lt;/h2&gt;
&lt;p&gt;Eye movements in reading offer a rich data source for understanding cognitive processes such as attention, memory, and language comprehension. Captured through eye-tracking technology, these movements include quick jumps called saccades and brief pauses known as fixations, where most information absorption takes place. Factors like text complexity and reader familiarity affect the duration of these fixations and the length of saccades. The parafoveal region of the eye also provides a &amp;lsquo;preview&amp;rsquo; of upcoming words during saccades, facilitating smoother reading. Lexical variables such as word frequency, predictability, and orthography further influence these eye movements, offering insights into ocular control and cognitive processes in reading.&lt;/p&gt;
&lt;p&gt;At LISN, we engage in targeted research projects to explore this complex landscape. For instance, one study examines the interaction between word frequency and contextual predictability in relation to parafoveal preview, aiming to understand their combined impact on fixation durations &lt;a href=&#34;http://localhost:1313/publication/2018-SWLYH-QJEP&#34;&gt;(Sereno et al., 2018)&lt;/a&gt;. Another research line investigates how altering the perceptual quality of the parafoveal preview might affect the processing of the previewed word&amp;rsquo;s spelling, subsequently influencing lexical selection in later fixations. Through these studies, LISN aims to clarify the multifaceted factors that influence eye movements in reading, thereby enriching broader theories of cognition and language processing.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;language-and-emotion&#34;&gt;Language and Emotion&lt;/h2&gt;
&lt;p&gt;The processing of emotion words involves a complex interplay between language and emotional cognition. One layer of complexity arises from the interaction between a word&amp;rsquo;s concreteness and its emotional valence. For example, concrete emotion words like &amp;ldquo;kiss&amp;rdquo; or &amp;ldquo;snake&amp;rdquo; often elicit stronger emotional and cognitive responses than abstract ones like &amp;ldquo;love&amp;rdquo; or &amp;ldquo;fear,&amp;rdquo; likely because they more easily evoke sensory experiences. Beyond this, the processing of emotion words is influenced by various factors such as the individual&amp;rsquo;s current emotional state, cultural background, and the context in which the word appears. For instance, a positive mood may facilitate the processing of positively-valenced words, while a negative mood could have the opposite effect.&lt;/p&gt;
&lt;p&gt;At LISN, we focus on these nuanced interactions. We examine how concreteness and emotional valence in word processing interact, particularly in the context of alexithymiaâ€”a condition characterised by difficulties in identifying and describing emotions &lt;a href=&#34;http://localhost:1313/publication/2018-YKBSOS-JEPLMC&#34;&gt;(Yao et al., 2018)&lt;/a&gt;. We also investigate how emotional experiences provide an embodied basis for understanding abstract concepts, thereby extending the &amp;rsquo;embodied cognition&amp;rsquo; framework to include emotional and abstract language. For example, the abstract concept of &amp;ldquo;freedom&amp;rdquo; may be more deeply understood through the emotional experience of relief or exhilaration &lt;a href=&#34;http://localhost:1313/publication/2013-YVWSOS-PlosONE&#34;&gt;(Yao et al., 2013)&lt;/a&gt;. Additionally, we explore the role of mood states in emotion word processing, investigating how they can alter the perceived emotional charge of words &lt;a href=&#34;http://localhost:1313/publication/2015-SSYTO-FrontierPsych&#34;&gt;(Sereno et al., 2015)&lt;/a&gt;. Through these research avenues, LISN aims to offer a comprehensive understanding of emotion word processing, enriching both theoretical frameworks and practical applications in cognitive science.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Inner Speech</title>
      <link>http://localhost:1313/research/innerspeech/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/research/innerspeech/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#hearing-words-off-the-page&#34;&gt;Hearing Words off the Page&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#varieties-of-inner-speech&#34;&gt;Varieties of Inner Speech&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#neural-mechanisms-of-inner-speech&#34;&gt;Neural Mechanisms of Inner Speech&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#inner-speech-in-self-consciousness&#34;&gt;Inner Speech in Self-Consciousness&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;hearing-words-off-the-page&#34;&gt;Hearing Words off the Page&lt;/h2&gt;
&lt;p&gt;Hearing inner voices while reading speech quotes is a phenomenon closely tied to inner speech, the internal dialogues that engages various cognitive and neural mechanisms. This experience can vary in tone, pitch, or accent based on the reader&amp;rsquo;s familiarity with characters or context, and it provides valuable insights into the interplay between language and perception. Inner speech during reading can affect comprehension, emotional engagement, and memory retention, and its experience can differ among individuals due to factors like reading proficiency, cognitive style, and mood. For example, some people report a more vivid inner voice when emotionally engaged with the text.&lt;/p&gt;
&lt;p&gt;At LISN, our research focuses on the experience of hearing inner voices during silent reading of speech quotes. Empirical evidence from our lab indicates increased neural activity in the auditory cortex &lt;a href=&#34;http://localhost:1313/publication/2011-YBS-JoCN&#34;&gt;(Yao, Belin, &amp;amp; Scheepers, 2011)&lt;/a&gt;, more synchronous auditory cortical oscillations &lt;a href=&#34;http://localhost:1313/publication/2021-YTBK-NeuroImage&#34;&gt;(Yao et al., 2021)&lt;/a&gt;, and eye movements that align with the speed of the inner voice &lt;a href=&#34;http://localhost:1313/publication/2011-YS-Cognition&#34;&gt;(Yao &amp;amp; Scheepers, 2011)&lt;/a&gt;. We explore underlying mechanisms and contributing factors, such as the hypothesis that learning to speak and read aloud may establish an automatic link between text and auditory experiences. Another line of inquiry considers that this inner voice simulates social interactions &lt;a href=&#34;http://localhost:1313/publication/2020-AMBMYF-JoCN&#34;&gt;(Alderson-Day et al., 2020)&lt;/a&gt;, potentially reinforced by the brain&amp;rsquo;s reward system as a prosocial mechanism. Through these research avenues, LISN aims to deepen our understanding of this complex aspect of language processing and cognition.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;varieties-of-inner-speech&#34;&gt;Varieties of Inner Speech&lt;/h2&gt;
&lt;p&gt;Inner speech manifests in various subtypes, each with distinct characteristics. Dialogic inner speech involves an internal dialogue where different perspectives are represented. Condensed inner speech is more abbreviated and lacks the full syntactic structure of external speech. Evaluative inner speech involves self-assessment or self-criticism, and motivational inner speech serves to encourage or motivate the individual. These subtypes offer valuable insights into the complexities of human cognition. To study them empirically, researchers use a range of methods. Self-report questionnaires capture individual experiences but can be subject to self-report biases. Experience sampling involves prompting participants at random times to report their inner speech, aiming to capture real-time data. Neuroimaging techniques like fMRI and EEG identify the brain regions activated during different types of inner speech. Think-aloud protocols involve participants verbalising their thought processes during tasks, capturing the structure and content of inner speech.&lt;/p&gt;
&lt;p&gt;At LISN, our research employs multiple methods to delve into inner speech subtypes. We use experience sampling in a range of cognitive tasks to understand the prevalence of inner speech subtypes in different situations. Think-aloud protocols help us explore the phenomenology of inner speech across various task conditions. Additionally, we use machine learning and EEG to identify the neural underpinnings of different inner speech subtypes. Through these research avenues, LISN aims to offer a comprehensive understanding of this complex aspect of language processing and cognition.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;neural-mechanisms-of-inner-speech&#34;&gt;Neural Mechanisms of Inner Speech&lt;/h2&gt;
&lt;p&gt;Inner speech, the internal dialogue or monologue that individuals engage in, is a complex neural activity with various subtypes and functions. The neural mechanisms behind inner speech involve multiple brain regions, including the left inferior frontal gyrus (IFG) for speech production and the superior temporal gyri/sulci (STG/STS) for speech comprehension. These regions often interact with other areas responsible for memory, attention, and emotional processing, such as the prefrontal cortex and the amygdala. Neuroimaging techniques like functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) have been instrumental in shedding light on these neural correlates. For example, fMRI studies have shown increased activity in the left IFG and STG during tasks requiring inner speech, while EEG studies have captured the real-time neural activity associated with different types of inner dialogue.&lt;/p&gt;
&lt;p&gt;At LISN, our research focuses on understanding these neural mechanisms and how they support inner speechâ€™s diverse phenomenology &lt;a href=&#34;http://localhost:1313/publication/2023-PPY-NeuroImage&#34;&gt;(Pratts, Pobric, &amp;amp; Yao, 2023)&lt;/a&gt;. We&amp;rsquo;ve found increased neural activity in auditory regions through fMRI &lt;a href=&#34;http://localhost:1313/publication/2011-YBS-JoCN&#34;&gt;(Yao, Belin, &amp;amp; Scheepers, 2011)&lt;/a&gt; and more synchronous auditory cortical oscillations in EEG &lt;a href=&#34;http://localhost:1313/publication/2021-YTBK-NeuroImage&#34;&gt;(Yao et al., 2021)&lt;/a&gt; associated with inner speech during quote reading. Our meta-analysis suggests that inner speech may be supported by both a motor-driven pathway, involving the left IFG, and an auditory pathway, involving auditory perceptual areas. These pathways could potentially underpin different inner speech subtypes &lt;a href=&#34;http://localhost:1313/publication/2023-PPY-NeuroImage&#34;&gt;(Pratts, Pobric, &amp;amp; Yao, 2023)&lt;/a&gt;. We are also employing machine learning to identify the neural features that characterise these subtypes, aiming for a more nuanced understanding of inner speech and its role in cognition. Through these research avenues, LISN seeks to deepen our understanding of the neural mechanisms of inner speech and its various subtypes.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;inner-speech-in-self-consciousness&#34;&gt;Inner Speech in Self-Consciousness&lt;/h2&gt;
&lt;p&gt;Inner speech serves as a critical interface between thought and consciousness, mediating self-awareness, intentionality, and subjective experience. While it has been a subject of philosophical inquiry for centuries, empirical research is relatively new. Studies have explored how inner speech contributes to different states and levels of consciousness, such as focused attention and mind-wandering. Understanding its role in consciousness can offer insights into self-awareness, intentional action, and even the boundaries of conscious experience. It also has implications for mental health, as disruptions in inner speech often occur in conditions like schizophrenia and certain types of depression.&lt;/p&gt;
&lt;p&gt;At LISN, we aim to empirically test the causal role of inner speech in self-awareness, capitalising on methodological advances and the discovery of aphantasia, a condition characterised by an inability to create visual imagery. We plan to objectively measure inner speech abilities in a range of tasks and use EEG to monitor inner speech in self-processing. Our research will pioneer data-driven classification of brain states related to inner speech and self-awareness. This approach could offer new prospects for understanding normal and altered states of consciousness, as well as related mental disorders like rumination, depression, and auditory verbal hallucinations. Through these research avenues, LISN seeks to deepen our understanding of the complex relationship between inner speech and consciousness.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Voice Hearing</title>
      <link>http://localhost:1313/research/voicehearing/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/research/voicehearing/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-continuum&#34;&gt;Voice Hearing Continuum&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-as-predictions&#34;&gt;Voice Hearing as Predictions&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-transition-risks&#34;&gt;Voice Hearing Transition Risks&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-interventions&#34;&gt;Voice Hearing Interventions&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;voice-hearing-continuum&#34;&gt;Voice Hearing Continuum&lt;/h2&gt;
&lt;p&gt;Voice hearing exists on a spectrum and is not limited to clinical populations. It involves a range of experiences, from hearing one&amp;rsquo;s name to complex dialogues, and can be distressing or benign. Neuroscientific and psychological studies have explored its neural and cognitive correlates, and cultural factors also play a role. Understanding this spectrum has implications for mental health treatment, challenging associated stigma and informing therapeutic interventions.&lt;/p&gt;
&lt;p&gt;At LISN, our research focuses on cognitive abilities and biases predictive of voice hearing tendencies across this spectrum. We particularly examine signal detection theory (SDT) performance, where both nonclinical and clinical voice hearers often exhibit an externalising bias, perceiving internal voices as originating externally. By comparing SDT performance among individuals, we aim to understand how this bias may be influenced by auditory verbal hallucination (AVH) proneness, variations in corollary discharge, memory inhibition, and other individual factors. Through this focus, LISN aims to offer a nuanced understanding of the cognitive mechanisms underlying the voice hearing spectrum.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-as-predictions&#34;&gt;Voice Hearing as Predictions&lt;/h2&gt;
&lt;p&gt;Voice hearing has been increasingly studied within the predictive coding framework, which describes perception as a process of hypothesis testing. In this framework, auditory verbal hallucinations (AVH) may arise from an imbalance between top-down predictions and bottom-up sensory input. Research has explored various factors contributing to this imbalance, such as neurotransmitter systems, cognitive biases, and socio-emotional factors. This perspective offers a generalised understanding of voice hearing and opens new avenues for prognosis, diagnosis and treatment.&lt;/p&gt;
&lt;p&gt;At LISN, we focus on experimentally manipulating predictions and sensory input to understand voice hearing better. Methods include conditioning, articulatory suppression, earworm induction, and exposure to different types of auditory noises. We assess the impacts of these manipulations on signal detection task (SDT) performance and self-reported voice hearing experiences &lt;a href=&#34;http://localhost:1313/publication/2023-MCPKY-FiN&#34;&gt;(Mak et al., 2023)&lt;/a&gt;. The goal is to test whether voice hearing can be causally explained in terms of changes in predictive brain mechanisms, which are natural, inherent mechanisms of the brain. Through this research, LISN aims to develop methods to characterise voice hearing tendencies across the population. This will help us understand its prevalence and transition risks to psychosis, while also helping to de-stigmatise the condition, especially among young people and those from ethnic minority backgrounds.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-transition-risks&#34;&gt;Voice Hearing Transition Risks&lt;/h2&gt;
&lt;p&gt;The transition from voice hearing to psychosis is a critical but relatively uncommon area of study in mental health research. While many people experience voice hearing without transitioning to clinical states like psychosis, understanding the factors that contribute to this transition is crucial for early intervention. Research has identified risk factors such as frequency and distress level of voice hearing, comorbid symptoms, and environmental stressors. Neurobiological markers and the concept of a &amp;ldquo;clinical high-risk state&amp;rdquo; have also been studied to identify those at increased risk.&lt;/p&gt;
&lt;p&gt;At LISN, we aim to understand the transition risks among nonclinical voice hearers, in collaboration with the Greater Manchester Mental Health NHS Foundation Trust. Our research focuses on understanding these risks as neurodevelopmental vulnerabilities, reflected in progressive voice hearing experiences. We also aim to understand the underlying cognitive and neural mechanisms that contribute to this transition. Through this targeted research, LISN seeks to offer insights into the factors that may lead to the transition from voice hearing to psychosis, with the goal of informing early intervention and prevention strategies.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-interventions&#34;&gt;Voice Hearing Interventions&lt;/h2&gt;
&lt;p&gt;Interventions for voice hearing have evolved to include a range of approaches, from pharmacological treatments to psychological therapies like CBT and mindfulness. Emerging techniques like neurostimulation and neurofeedback offer targeted, brain-based interventions. Neurostimulation methods like TMS and tDCS modulate neural activity, while neurofeedback teaches self-regulation through real-time brain monitoring. These methods are less reliant on medication and offer the promise of more personalised treatment.&lt;/p&gt;
&lt;p&gt;At LISN, our focus is on developing an EEG-tDCS closed-loop type of online intervention for voice hearing. The EEG identifies the states of voice hearing in real-time, and tDCS aims to counter it before it escalates into full-blown psychotic episodes. While these are still drawing board ideas, they represent the ultimate goal of our lab in studying voice hearing. Through this innovative approach, LISN aims to offer a more immediate and targeted intervention, potentially revolutionising the treatment landscape for voice hearing.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
