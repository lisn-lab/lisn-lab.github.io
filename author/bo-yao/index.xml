<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Bo Yao | LISN Lab</title>
    <link>https://lisn-lab.org/author/bo-yao/</link>
      <atom:link href="https://lisn-lab.org/author/bo-yao/index.xml" rel="self" type="application/rss+xml" />
    <description>Bo Yao</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Wed, 09 Apr 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://lisn-lab.org/author/bo-yao/avatar_hu_d6438ad4329ad00b.jpg</url>
      <title>Bo Yao</title>
      <link>https://lisn-lab.org/author/bo-yao/</link>
    </image>
    
    <item>
      <title>Calling for Artists to Create Artworks of Inner Speech for Young People</title>
      <link>https://lisn-lab.org/post/20250409-voicesofthemind-artist/</link>
      <pubDate>Wed, 09 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/post/20250409-voicesofthemind-artist/</guid>
      <description>&lt;h2 id=&#34;project-overview--vision&#34;&gt;Project Overview &amp;amp; Vision&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://lisn-lab.org/projects/voicesofthemind/&#34;&gt;‘Voices of the Mind’&lt;/a&gt; is a public engagement project that explores inner speech - the internal dialogue we have with our minds.&lt;/p&gt;
&lt;p&gt;We aim to empower young people aged 14-18 from diverse backgrounds with knowledge about their inner experiences, create interdisciplinary dialogue between science and art, reduce stigma around different thought patterns, and make neuroscience accessible to those traditionally underrepresented in STEM fields.&lt;/p&gt;
&lt;p&gt;We are seeking artists to create engaging works that interpret and visualise inner speech / thoughts, helping young people understand, relate to, and reflect upon their inner speech while sparking curiosity about neuroscience and AI. Your work will feature in public exhibitions, workshops, and online platforms.&lt;/p&gt;
&lt;h2 id=&#34;commission-details&#34;&gt;Commission Details&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Total Budget Available&lt;/strong&gt;: £4,500 (can be allocated to one artist or be divided among multiple artists)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Timeline&lt;/strong&gt;: Commissions to be completed by end of September 2025&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Theme&lt;/strong&gt;: Inner speech, inner thoughts, and the experience of hearing voices within our minds&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;u&gt;&lt;strong&gt;Focus&lt;/strong&gt;&lt;/u&gt;: We particularly welcome proposals that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make abstract thought processes tangible and relatable&lt;/li&gt;
&lt;li&gt;Represent the diversity of inner speech / thought experiences&lt;/li&gt;
&lt;li&gt;Create opportunities for reflection on how we think and talk to ourselves in the mind&lt;/li&gt;
&lt;li&gt;Explore the boundaries between typical inner speech and more intrusive thoughts&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;u&gt;&lt;strong&gt;Format&lt;/strong&gt;&lt;/u&gt;: We prioritise:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Digital&lt;/strong&gt; art that can be shared online and incorporated into our digital platforms&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Portable&lt;/strong&gt; physical installations that can travel between multiple events&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Interactive&lt;/strong&gt; elements that engage audiences and encourage participation&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;u&gt;&lt;strong&gt;Example Project Ideas&lt;/strong&gt;&lt;/u&gt;: We welcome innovative approaches beyond these suggestions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;u&gt;Animated Short Film&lt;/u&gt;: A visual journey through inner thoughts, perhaps showing how they flow, interact, or evolve&lt;/li&gt;
&lt;li&gt;&lt;u&gt;Interactive VR Environment&lt;/u&gt;: An immersive virtual space where users experience different forms of inner speech as they navigate (could be a VR app or a 2D POV film illustrating spontaneous thought patterns)&lt;/li&gt;
&lt;li&gt;&lt;u&gt;Audio Installation&lt;/u&gt;: A layered soundscape using multiple voices to represent the variety and complexity of inner speech (we can provide recordings of real self-talk as source material)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;submission-requirements&#34;&gt;Submission Requirements&lt;/h2&gt;
&lt;p&gt;Please provide:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Artist statement explaining your motivation and interest in this project&lt;/li&gt;
&lt;li&gt;A concept description&lt;/li&gt;
&lt;li&gt;Visual/auditory references, sketches or examples of the proposed work&lt;/li&gt;
&lt;li&gt;Technical requirements, production plan, and timeline for completion&lt;/li&gt;
&lt;li&gt;Budget breakdown&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;selection-criteria&#34;&gt;Selection Criteria&lt;/h2&gt;
&lt;p&gt;Proposals will be evaluated on:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Artistic quality and innovation&lt;/li&gt;
&lt;li&gt;Feasibility within budget and timeline&lt;/li&gt;
&lt;li&gt;Alignment with project aims and audience&lt;/li&gt;
&lt;li&gt;Intractability, portability and adaptability for various settings&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;contact-and-submission&#34;&gt;Contact and Submission&lt;/h2&gt;
&lt;p&gt;Please submit your proposal to &lt;a href=&#34;mailto:b.yao1@lancaster.ac.uk&#34;&gt;b.yao1@lancaster.ac.uk&lt;/a&gt; by &lt;strong&gt;30th May 2025&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;We particularly encourage applications from artists from diverse backgrounds and those with connections to Northwest England.&lt;/p&gt;
&lt;br&gt;
More Info:












  












&lt;div class=&#34;card-simple view-card&#34;&gt;

  
    


&lt;div class=&#34;article-metadata&#34;&gt;

  
  

  

  

  

  
  
  
  

  
  

&lt;/div&gt;

  

  
  
  
    
    
    &lt;a href=&#34;https://lisn-lab.org/projects/voicesofthemind/&#34; &gt;
      &lt;div class=&#34;img-hover-zoom&#34;&gt;
        &lt;img src=&#34;https://lisn-lab.org/media/voicesofthemind_royalsociety_hu_ca2299c553883805.webp&#34; height=&#34;455&#34; width=&#34;808&#34;
            class=&#34;article-banner&#34; alt=&#34;Voices of the Mind&#34; loading=&#34;lazy&#34;&gt;
      &lt;/div&gt;
    &lt;/a&gt;
  

  &lt;div class=&#34;section-subheading article-title mb-1 mt-3&#34;&gt;
    &lt;a href=&#34;https://lisn-lab.org/projects/voicesofthemind/&#34; &gt;Voices of the Mind&lt;/a&gt;
  &lt;/div&gt;

  

  

&lt;/div&gt;



</description>
    </item>
    
    <item>
      <title>LISN Lab Celebrates a Memorable EPS Lancaster Experience</title>
      <link>https://lisn-lab.org/post/20250407-epslancaster/</link>
      <pubDate>Mon, 07 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/post/20250407-epslancaster/</guid>
      <description>&lt;p&gt;What a vibrant few days we had at the Experimental Psychology Society conference in Lancaster! The LISN Lab team returned to the lab energised, inspired, and with notebooks full of new ideas after engaging with the psychological research community.&lt;/p&gt;
&lt;p&gt;The conference halls buzzed with excitement as our researchers shared their latest discoveries. We dived deep into the fascinating world of how languages, which place different emphases on the subject or the overall topic, are underpinned by different structural representations in the brain. Meanwhile, conversations flourished around our presentations on how our life experiences shape abstract thinking - it turns out those episodic memories don&amp;rsquo;t just help us remember the past, they fundamentally influence how we mentally construct concepts like &amp;ldquo;freedom&amp;rdquo; or &amp;ldquo;justice&amp;rdquo;.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;ve really enjoyed the discussions about our work on inner speech. When that little voice in your head speaks, how do the motor and auditory speech mechanisms work together, differently and dynamically? Our findings on how perceptual reactivation plays a key role in shaping inner speech experiences into different forms prompted many attendees to reflect on their own inner speech experiences.&lt;/p&gt;

















&lt;div class=&#34;gallery-grid&#34;&gt;

  
  
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-2025eps&#34; href=&#34;https://lisn-lab.org/media/albums/2025eps/guyutalk.jpeg&#34; &gt;
      &lt;img src=&#34;https://lisn-lab.org/media/albums/2025eps/guyutalk_hu_c9cc25426814203b.webp&#34; loading=&#34;lazy&#34; alt=&#34;guyutalk.jpeg&#34; width=&#34;250&#34; height=&#34;188&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-2025eps&#34; href=&#34;https://lisn-lab.org/media/albums/2025eps/jiaxuantalk.jpeg&#34; &gt;
      &lt;img src=&#34;https://lisn-lab.org/media/albums/2025eps/jiaxuantalk_hu_4a76a9246dd84a8f.webp&#34; loading=&#34;lazy&#34; alt=&#34;jiaxuantalk.jpeg&#34; width=&#34;250&#34; height=&#34;203&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-2025eps&#34; href=&#34;https://lisn-lab.org/media/albums/2025eps/poster_guyujiaxuan.jpeg&#34; &gt;
      &lt;img src=&#34;https://lisn-lab.org/media/albums/2025eps/poster_guyujiaxuan_hu_5022cb7283dfd511.webp&#34; loading=&#34;lazy&#34; alt=&#34;poster_guyujiaxuan.jpeg&#34; width=&#34;188&#34; height=&#34;250&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  
    
    
    
    
    
  
  
  &lt;div class=&#34;gallery-item gallery-item--medium&#34;&gt;
    &lt;a data-fancybox=&#34;gallery-2025eps&#34; href=&#34;https://lisn-lab.org/media/albums/2025eps/poster.jpeg&#34; &gt;
      &lt;img src=&#34;https://lisn-lab.org/media/albums/2025eps/poster_hu_fd370e65bf96f9c8.webp&#34; loading=&#34;lazy&#34; alt=&#34;poster.jpeg&#34; width=&#34;188&#34; height=&#34;250&#34;&gt;
    &lt;/a&gt;
  &lt;/div&gt;
  

&lt;/div&gt;

&lt;p&gt;The entire event flowed seamlessly thanks to the tremendous efforts of Padraic, Alice, and all the local organisers who transformed academic presentations into a genuine community experience. Their thoughtful planning created spaces not just for formal knowledge exchange, but for the kind of spontaneous interactions that often spark the most innovative ideas.&lt;/p&gt;
&lt;p&gt;As we settle back into our research routines, we carry with us new connections, fresh insights, and renewed enthusiasm for our research questions. Stay tuned as we build on these experiences in our upcoming work!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>It&#39;s about time: Rhythmic foundations of inner thought</title>
      <link>https://lisn-lab.org/publication/2025-y-physlife/</link>
      <pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2025-y-physlife/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Transcranial electrical stimulation modulates emotional experience and metabolites in the prefrontal cortex in a donation task</title>
      <link>https://lisn-lab.org/publication/2024-mbmcabmhmmp-scirep/</link>
      <pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2024-mbmcabmhmmp-scirep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Emotion processing in concrete and abstract words: Evidence from eye fixations during reading</title>
      <link>https://lisn-lab.org/publication/2024-ysbms-cognemo/</link>
      <pubDate>Wed, 05 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2024-ysbms-cognemo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bridging phenomenology and neural mechanisms of inner speech: ALE meta-analysis on egocentricity and spontaneity in a dual-mechanistic framework</title>
      <link>https://lisn-lab.org/publication/2023-ppy-neuroimage/</link>
      <pubDate>Fri, 29 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2023-ppy-neuroimage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Investigating the lateralisation of experimentally induced auditory verbal hallucinations</title>
      <link>https://lisn-lab.org/publication/2023-mcpky-fin/</link>
      <pubDate>Thu, 06 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2023-mcpky-fin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What can size tell us about abstract conceptual processing?</title>
      <link>https://lisn-lab.org/publication/2022-yts-jml/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2022-yts-jml/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reading direct speech quotes increases theta phase-locking: Evidence for cortical tracking of inner speech?</title>
      <link>https://lisn-lab.org/publication/2021-ytbk-neuroimage/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2021-ytbk-neuroimage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mental simulations of phonological representations are causally linked to silent reading of direct versus indirect speech</title>
      <link>https://lisn-lab.org/publication/2021-y-jocognition/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2021-y-jocognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Processing speech and thoughts during silent reading: Direct reference effects for speech by fictional characters in voice-selective auditory cortex and a Theory-of-Mind network</title>
      <link>https://lisn-lab.org/publication/2020-ambmyf-jocn/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2020-ambmyf-jocn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Glasgow Norms: Ratings of 5,500 words on nine scales</title>
      <link>https://lisn-lab.org/publication/2019-skbys-brm/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2019-skbys-brm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Direct speech quotations promote low relative-clause attachment in silent reading of English</title>
      <link>https://lisn-lab.org/publication/2018-ys-cognition/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-ys-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>‘It’s hard to write a good article’: The online comprehension of excuses as indirect replies</title>
      <link>https://lisn-lab.org/publication/2018-swlyh-qjep/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-swlyh-qjep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Comprehension of indirect requests is influenced by their degree of imposition</title>
      <link>https://lisn-lab.org/publication/2018-slwyh-discourseprocesses/</link>
      <pubDate>Sat, 17 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-slwyh-discourseprocesses/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Differential emotional processing in concrete and abstract words</title>
      <link>https://lisn-lab.org/publication/2018-ykbsos-jeplmc/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-ykbsos-jeplmc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Testing the limits of contextual constraint: Interactions with word frequency and parafoveal preview during fluent reading</title>
      <link>https://lisn-lab.org/publication/2018-shsyo-qjep/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-shsyo-qjep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Walking blindfolded unveils unique contributions of behavioural approach and inhibition to lateral spatial bias</title>
      <link>https://lisn-lab.org/publication/2016-wavy-cognition/</link>
      <pubDate>Mon, 01 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2016-wavy-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Emotion word processing: Does mood make a difference?</title>
      <link>https://lisn-lab.org/publication/2015-ssyto-frontierpsych/</link>
      <pubDate>Mon, 24 Aug 2015 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2015-ssyto-frontierpsych/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inner voice experiences during processing of direct and indirect speech</title>
      <link>https://lisn-lab.org/publication/2015-ys-eaipisp/</link>
      <pubDate>Wed, 24 Jun 2015 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2015-ys-eaipisp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Familiarity with interest breeds gossip: Contributions of emotion, expectation, and reputation</title>
      <link>https://lisn-lab.org/publication/2014-ysmos-plosone/</link>
      <pubDate>Wed, 13 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2014-ysmos-plosone/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Semantic size of abstract concepts: It gets emotional when you can’t see it</title>
      <link>https://lisn-lab.org/publication/2013-yvwsos-plosone/</link>
      <pubDate>Wed, 25 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2013-yvwsos-plosone/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain ‘talks over’ boring quotes: Top-down activation of voice-selective areas while listening to monotonous direct speech quotations</title>
      <link>https://lisn-lab.org/publication/2012-ybs-neuroimage/</link>
      <pubDate>Sun, 15 Apr 2012 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2012-ybs-neuroimage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contextual modulation of reading rate for direct versus indirect speech quotations</title>
      <link>https://lisn-lab.org/publication/2011-ys-cognition/</link>
      <pubDate>Thu, 01 Dec 2011 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2011-ys-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Silent reading of direct versus indirect speech activates voice-selective areas in the auditory cortex</title>
      <link>https://lisn-lab.org/publication/2011-ybs-jocn/</link>
      <pubDate>Sat, 01 Oct 2011 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2011-ybs-jocn/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
