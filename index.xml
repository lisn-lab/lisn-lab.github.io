<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LISN Lab</title>
    <link>http://localhost:1313/</link>
      <atom:link href="http://localhost:1313/index.xml" rel="self" type="application/rss+xml" />
    <description>LISN Lab</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu12750140480456391776.png</url>
      <title>LISN Lab</title>
      <link>http://localhost:1313/</link>
    </image>
    
    <item>
      <title>Language</title>
      <link>http://localhost:1313/research/language/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/research/language/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#abstract-concepts&#34;&gt;Abstract Concepts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#structural-processing&#34;&gt;Structural Processing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#eye-movements-in-reading&#34;&gt;Eye Movements in Reading&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#language-and-emotion&#34;&gt;Language and Emotion&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;abstract-concepts&#34;&gt;Abstract Concepts&lt;/h2&gt;
&lt;p&gt;Abstract concepts like &amp;ldquo;love&amp;rdquo; or &amp;ldquo;trust&amp;rdquo; pose a unique challenge in cognitive science. Unlike concrete concepts such as &amp;ldquo;red,&amp;rdquo; which derive meaning from direct sensory experiences, abstract concepts lack physical referents. This absence raises questions about how such concepts are represented in the mind and complicates the prevailing &amp;rsquo;embodied&amp;rsquo; theory of concept representation, which suggests that concepts gain meaning through bodily experiences.&lt;/p&gt;
&lt;p&gt;At LISN, we tackle these challenges by exploring alternative grounding for abstract concepts. We investigate whether emotional or metaphorical experiences provide the basis for understanding abstract words. For example, &amp;rsquo;trust&amp;rsquo; is often considered a &amp;lsquo;big&amp;rsquo; concept because it elicits strong emotions &lt;a href=&#34;http://localhost:1313/publication/2013-YVWSOS-PlosONE&#34;&gt;(Yao et al., 2013)&lt;/a&gt; and is metaphorically associated with large objects like &amp;lsquo;castle&amp;rsquo; or &amp;lsquo;cathedral&amp;rsquo; &lt;a href=&#34;http://localhost:1313/publication/2022-YTS-JML&#34;&gt;(Yao, Taylor, &amp;amp; Sereno, 2022)&lt;/a&gt;. Our research also examines the possibility that abstract concepts have a more episodic and context-dependent grounding compared to concrete ones. For instance, the concept of &amp;rsquo;love&amp;rsquo; can vary significantly depending on the context, such as a romantic dinner or a care home, unlike more concrete concepts like &amp;lsquo;cat,&amp;rsquo; which consistently evoke features like fur and paws. We extend this inquiry to understand how embodied experiences influence language comprehension across various contexts and life stages.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;structural-processing&#34;&gt;Structural Processing&lt;/h2&gt;
&lt;p&gt;Structural processing in language is a complex cognitive function that extends beyond mere syntax. It involves breaking down sentences into components such as subjects, verbs, and objects, and understanding their interrelationships to extract meaning. This function also intersects with other cognitive domains like prosody - the intonation in spoken sentences - and arithmetic operations, highlighting its role as a domain-general mechanism crucial for structuring language, cognition, and communication.&lt;/p&gt;
&lt;p&gt;At LISN, our focus is twofold. First, we explore the link between implicit prosody in reading, commonly known as &amp;ldquo;inner speech,&amp;rdquo; and syntactic processing. This helps us understand how the &amp;lsquo;melody&amp;rsquo; of language in our minds influences sentence interpretation &lt;a href=&#34;http://localhost:1313/publication/2018-YS-Cognition&#34;&gt;(Yao &amp;amp; Scheepers, 2018)&lt;/a&gt;. Second, we study how sentence structures in different languages affect cognition among their speakers. For example, Chinese sentences often omit subjects and focus on topics, whereas English sentences require subjects and emphasise them. This difference could lead to varying attentional focuses and mental representations. We also examine the contrasting structures between left-branching languages like Chinese and right-branching languages like English, suggesting different structural hierarchies between languages. Through these investigations, we aim to untangle the complexities of structural processing and its influence on cognition and communication.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;eye-movements-in-reading&#34;&gt;Eye Movements in Reading&lt;/h2&gt;
&lt;p&gt;Eye movements in reading offer a rich data source for understanding cognitive processes such as attention, memory, and language comprehension. Captured through eye-tracking technology, these movements include quick jumps called saccades and brief pauses known as fixations, where most information absorption takes place. Factors like text complexity and reader familiarity affect the duration of these fixations and the length of saccades. The parafoveal region of the eye also provides a &amp;lsquo;preview&amp;rsquo; of upcoming words during saccades, facilitating smoother reading. Lexical variables such as word frequency, predictability, and orthography further influence these eye movements, offering insights into ocular control and cognitive processes in reading.&lt;/p&gt;
&lt;p&gt;At LISN, we engage in targeted research projects to explore this complex landscape. For instance, one study examines the interaction between word frequency and contextual predictability in relation to parafoveal preview, aiming to understand their combined impact on fixation durations &lt;a href=&#34;http://localhost:1313/publication/2018-SWLYH-QJEP&#34;&gt;(Sereno et al., 2018)&lt;/a&gt;. Another research line investigates how altering the perceptual quality of the parafoveal preview might affect the processing of the previewed word&amp;rsquo;s spelling, subsequently influencing lexical selection in later fixations. Through these studies, LISN aims to clarify the multifaceted factors that influence eye movements in reading, thereby enriching broader theories of cognition and language processing.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;language-and-emotion&#34;&gt;Language and Emotion&lt;/h2&gt;
&lt;p&gt;The processing of emotion words involves a complex interplay between language and emotional cognition. One layer of complexity arises from the interaction between a word&amp;rsquo;s concreteness and its emotional valence. For example, concrete emotion words like &amp;ldquo;kiss&amp;rdquo; or &amp;ldquo;snake&amp;rdquo; often elicit stronger emotional and cognitive responses than abstract ones like &amp;ldquo;love&amp;rdquo; or &amp;ldquo;fear,&amp;rdquo; likely because they more easily evoke sensory experiences. Beyond this, the processing of emotion words is influenced by various factors such as the individual&amp;rsquo;s current emotional state, cultural background, and the context in which the word appears. For instance, a positive mood may facilitate the processing of positively-valenced words, while a negative mood could have the opposite effect.&lt;/p&gt;
&lt;p&gt;At LISN, we focus on these nuanced interactions. We examine how concreteness and emotional valence in word processing interact, particularly in the context of alexithymia—a condition characterised by difficulties in identifying and describing emotions &lt;a href=&#34;http://localhost:1313/publication/2018-YKBSOS-JEPLMC&#34;&gt;(Yao et al., 2018)&lt;/a&gt;. We also investigate how emotional experiences provide an embodied basis for understanding abstract concepts, thereby extending the &amp;rsquo;embodied cognition&amp;rsquo; framework to include emotional and abstract language. For example, the abstract concept of &amp;ldquo;freedom&amp;rdquo; may be more deeply understood through the emotional experience of relief or exhilaration &lt;a href=&#34;http://localhost:1313/publication/2013-YVWSOS-PlosONE&#34;&gt;(Yao et al., 2013)&lt;/a&gt;. Additionally, we explore the role of mood states in emotion word processing, investigating how they can alter the perceived emotional charge of words &lt;a href=&#34;http://localhost:1313/publication/2015-SSYTO-FrontierPsych&#34;&gt;(Sereno et al., 2015)&lt;/a&gt;. Through these research avenues, LISN aims to offer a comprehensive understanding of emotion word processing, enriching both theoretical frameworks and practical applications in cognitive science.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Inner Speech</title>
      <link>http://localhost:1313/research/innerspeech/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/research/innerspeech/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#hearing-words-off-the-page&#34;&gt;Hearing Words off the Page&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#varieties-of-inner-speech&#34;&gt;Varieties of Inner Speech&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#neural-mechanisms-of-inner-speech&#34;&gt;Neural Mechanisms of Inner Speech&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#inner-speech-in-self-consciousness&#34;&gt;Inner Speech in Self-Consciousness&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;hearing-words-off-the-page&#34;&gt;Hearing Words off the Page&lt;/h2&gt;
&lt;p&gt;Hearing inner voices while reading speech quotes is a phenomenon closely tied to inner speech, the internal dialogues that engages various cognitive and neural mechanisms. This experience can vary in tone, pitch, or accent based on the reader&amp;rsquo;s familiarity with characters or context, and it provides valuable insights into the interplay between language and perception. Inner speech during reading can affect comprehension, emotional engagement, and memory retention, and its experience can differ among individuals due to factors like reading proficiency, cognitive style, and mood. For example, some people report a more vivid inner voice when emotionally engaged with the text.&lt;/p&gt;
&lt;p&gt;At LISN, our research focuses on the experience of hearing inner voices during silent reading of speech quotes. Empirical evidence from our lab indicates increased neural activity in the auditory cortex &lt;a href=&#34;http://localhost:1313/publication/2011-YBS-JoCN&#34;&gt;(Yao, Belin, &amp;amp; Scheepers, 2011)&lt;/a&gt;, more synchronous auditory cortical oscillations &lt;a href=&#34;http://localhost:1313/publication/2021-YTBK-NeuroImage&#34;&gt;(Yao et al., 2021)&lt;/a&gt;, and eye movements that align with the speed of the inner voice &lt;a href=&#34;http://localhost:1313/publication/2011-YS-Cognition&#34;&gt;(Yao &amp;amp; Scheepers, 2011)&lt;/a&gt;. We explore underlying mechanisms and contributing factors, such as the hypothesis that learning to speak and read aloud may establish an automatic link between text and auditory experiences. Another line of inquiry considers that this inner voice simulates social interactions &lt;a href=&#34;http://localhost:1313/publication/2020-AMBMYF-JoCN&#34;&gt;(Alderson-Day et al., 2020)&lt;/a&gt;, potentially reinforced by the brain&amp;rsquo;s reward system as a prosocial mechanism. Through these research avenues, LISN aims to deepen our understanding of this complex aspect of language processing and cognition.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;varieties-of-inner-speech&#34;&gt;Varieties of Inner Speech&lt;/h2&gt;
&lt;p&gt;Inner speech manifests in various subtypes, each with distinct characteristics. Dialogic inner speech involves an internal dialogue where different perspectives are represented. Condensed inner speech is more abbreviated and lacks the full syntactic structure of external speech. Evaluative inner speech involves self-assessment or self-criticism, and motivational inner speech serves to encourage or motivate the individual. These subtypes offer valuable insights into the complexities of human cognition. To study them empirically, researchers use a range of methods. Self-report questionnaires capture individual experiences but can be subject to self-report biases. Experience sampling involves prompting participants at random times to report their inner speech, aiming to capture real-time data. Neuroimaging techniques like fMRI and EEG identify the brain regions activated during different types of inner speech. Think-aloud protocols involve participants verbalising their thought processes during tasks, capturing the structure and content of inner speech.&lt;/p&gt;
&lt;p&gt;At LISN, our research employs multiple methods to delve into inner speech subtypes. We use experience sampling in a range of cognitive tasks to understand the prevalence of inner speech subtypes in different situations. Think-aloud protocols help us explore the phenomenology of inner speech across various task conditions. Additionally, we use machine learning and EEG to identify the neural underpinnings of different inner speech subtypes. Through these research avenues, LISN aims to offer a comprehensive understanding of this complex aspect of language processing and cognition.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;neural-mechanisms-of-inner-speech&#34;&gt;Neural Mechanisms of Inner Speech&lt;/h2&gt;
&lt;p&gt;Inner speech, the internal dialogue or monologue that individuals engage in, is a complex neural activity with various subtypes and functions. The neural mechanisms behind inner speech involve multiple brain regions, including the left inferior frontal gyrus (IFG) for speech production and the superior temporal gyri/sulci (STG/STS) for speech comprehension. These regions often interact with other areas responsible for memory, attention, and emotional processing, such as the prefrontal cortex and the amygdala. Neuroimaging techniques like functional magnetic resonance imaging (fMRI) and electroencephalography (EEG) have been instrumental in shedding light on these neural correlates. For example, fMRI studies have shown increased activity in the left IFG and STG during tasks requiring inner speech, while EEG studies have captured the real-time neural activity associated with different types of inner dialogue.&lt;/p&gt;
&lt;p&gt;At LISN, our research focuses on understanding these neural mechanisms and how they support inner speech’s diverse phenomenology &lt;a href=&#34;http://localhost:1313/publication/2023-PPY-NeuroImage&#34;&gt;(Pratts, Pobric, &amp;amp; Yao, 2023)&lt;/a&gt;. We&amp;rsquo;ve found increased neural activity in auditory regions through fMRI &lt;a href=&#34;http://localhost:1313/publication/2011-YBS-JoCN&#34;&gt;(Yao, Belin, &amp;amp; Scheepers, 2011)&lt;/a&gt; and more synchronous auditory cortical oscillations in EEG &lt;a href=&#34;http://localhost:1313/publication/2021-YTBK-NeuroImage&#34;&gt;(Yao et al., 2021)&lt;/a&gt; associated with inner speech during quote reading. Our meta-analysis suggests that inner speech may be supported by both a motor-driven pathway, involving the left IFG, and an auditory pathway, involving auditory perceptual areas. These pathways could potentially underpin different inner speech subtypes &lt;a href=&#34;http://localhost:1313/publication/2023-PPY-NeuroImage&#34;&gt;(Pratts, Pobric, &amp;amp; Yao, 2023)&lt;/a&gt;. We are also employing machine learning to identify the neural features that characterise these subtypes, aiming for a more nuanced understanding of inner speech and its role in cognition. Through these research avenues, LISN seeks to deepen our understanding of the neural mechanisms of inner speech and its various subtypes.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;inner-speech-in-self-consciousness&#34;&gt;Inner Speech in Self-Consciousness&lt;/h2&gt;
&lt;p&gt;Inner speech serves as a critical interface between thought and consciousness, mediating self-awareness, intentionality, and subjective experience. While it has been a subject of philosophical inquiry for centuries, empirical research is relatively new. Studies have explored how inner speech contributes to different states and levels of consciousness, such as focused attention and mind-wandering. Understanding its role in consciousness can offer insights into self-awareness, intentional action, and even the boundaries of conscious experience. It also has implications for mental health, as disruptions in inner speech often occur in conditions like schizophrenia and certain types of depression.&lt;/p&gt;
&lt;p&gt;At LISN, we aim to empirically test the causal role of inner speech in self-awareness, capitalising on methodological advances and the discovery of aphantasia, a condition characterised by an inability to create visual imagery. We plan to objectively measure inner speech abilities in a range of tasks and use EEG to monitor inner speech in self-processing. Our research will pioneer data-driven classification of brain states related to inner speech and self-awareness. This approach could offer new prospects for understanding normal and altered states of consciousness, as well as related mental disorders like rumination, depression, and auditory verbal hallucinations. Through these research avenues, LISN seeks to deepen our understanding of the complex relationship between inner speech and consciousness.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Voice Hearing</title>
      <link>http://localhost:1313/research/voicehearing/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/research/voicehearing/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-continuum&#34;&gt;Voice Hearing Continuum&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-as-predictions&#34;&gt;Voice Hearing as Predictions&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-transition-risks&#34;&gt;Voice Hearing Transition Risks&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-interventions&#34;&gt;Voice Hearing Interventions&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;h2 id=&#34;voice-hearing-continuum&#34;&gt;Voice Hearing Continuum&lt;/h2&gt;
&lt;p&gt;Voice hearing exists on a spectrum and is not limited to clinical populations. It involves a range of experiences, from hearing one&amp;rsquo;s name to complex dialogues, and can be distressing or benign. Neuroscientific and psychological studies have explored its neural and cognitive correlates, and cultural factors also play a role. Understanding this spectrum has implications for mental health treatment, challenging associated stigma and informing therapeutic interventions.&lt;/p&gt;
&lt;p&gt;At LISN, our research focuses on cognitive abilities and biases predictive of voice hearing tendencies across this spectrum. We particularly examine signal detection theory (SDT) performance, where both nonclinical and clinical voice hearers often exhibit an externalising bias, perceiving internal voices as originating externally. By comparing SDT performance among individuals, we aim to understand how this bias may be influenced by auditory verbal hallucination (AVH) proneness, variations in corollary discharge, memory inhibition, and other individual factors. Through this focus, LISN aims to offer a nuanced understanding of the cognitive mechanisms underlying the voice hearing spectrum.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-as-predictions&#34;&gt;Voice Hearing as Predictions&lt;/h2&gt;
&lt;p&gt;Voice hearing has been increasingly studied within the predictive coding framework, which describes perception as a process of hypothesis testing. In this framework, auditory verbal hallucinations (AVH) may arise from an imbalance between top-down predictions and bottom-up sensory input. Research has explored various factors contributing to this imbalance, such as neurotransmitter systems, cognitive biases, and socio-emotional factors. This perspective offers a generalised understanding of voice hearing and opens new avenues for prognosis, diagnosis and treatment.&lt;/p&gt;
&lt;p&gt;At LISN, we focus on experimentally manipulating predictions and sensory input to understand voice hearing better. Methods include conditioning, articulatory suppression, earworm induction, and exposure to different types of auditory noises. We assess the impacts of these manipulations on signal detection task (SDT) performance and self-reported voice hearing experiences &lt;a href=&#34;http://localhost:1313/publication/2023-MCPKY-FiN&#34;&gt;(Mak et al., 2023)&lt;/a&gt;. The goal is to test whether voice hearing can be causally explained in terms of changes in predictive brain mechanisms, which are natural, inherent mechanisms of the brain. Through this research, LISN aims to develop methods to characterise voice hearing tendencies across the population. This will help us understand its prevalence and transition risks to psychosis, while also helping to de-stigmatise the condition, especially among young people and those from ethnic minority backgrounds.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-transition-risks&#34;&gt;Voice Hearing Transition Risks&lt;/h2&gt;
&lt;p&gt;The transition from voice hearing to psychosis is a critical but relatively uncommon area of study in mental health research. While many people experience voice hearing without transitioning to clinical states like psychosis, understanding the factors that contribute to this transition is crucial for early intervention. Research has identified risk factors such as frequency and distress level of voice hearing, comorbid symptoms, and environmental stressors. Neurobiological markers and the concept of a &amp;ldquo;clinical high-risk state&amp;rdquo; have also been studied to identify those at increased risk.&lt;/p&gt;
&lt;p&gt;At LISN, we aim to understand the transition risks among nonclinical voice hearers, in collaboration with the Greater Manchester Mental Health NHS Foundation Trust. Our research focuses on understanding these risks as neurodevelopmental vulnerabilities, reflected in progressive voice hearing experiences. We also aim to understand the underlying cognitive and neural mechanisms that contribute to this transition. Through this targeted research, LISN seeks to offer insights into the factors that may lead to the transition from voice hearing to psychosis, with the goal of informing early intervention and prevention strategies.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-interventions&#34;&gt;Voice Hearing Interventions&lt;/h2&gt;
&lt;p&gt;Interventions for voice hearing have evolved to include a range of approaches, from pharmacological treatments to psychological therapies like CBT and mindfulness. Emerging techniques like neurostimulation and neurofeedback offer targeted, brain-based interventions. Neurostimulation methods like TMS and tDCS modulate neural activity, while neurofeedback teaches self-regulation through real-time brain monitoring. These methods are less reliant on medication and offer the promise of more personalised treatment.&lt;/p&gt;
&lt;p&gt;At LISN, our focus is on developing an EEG-tDCS closed-loop type of online intervention for voice hearing. The EEG identifies the states of voice hearing in real-time, and tDCS aims to counter it before it escalates into full-blown psychotic episodes. While these are still drawing board ideas, they represent the ultimate goal of our lab in studying voice hearing. Through this innovative approach, LISN aims to offer a more immediate and targeted intervention, potentially revolutionising the treatment landscape for voice hearing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>STARS Squad Kicks Off Journal Club with a Bang!</title>
      <link>http://localhost:1313/post/20241030-stars-journalclub/</link>
      <pubDate>Wed, 30 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/20241030-stars-journalclub/</guid>
      <description>&lt;p&gt;Our new STARS squad launched their first journal club this week, and it was a hit! Maisie led an engaging discussion on the Variety of Inner Speech Questionnaire-Revised, sparking interesting conversations about inner speech, cultural norms, and individual experiences.&lt;/p&gt;
&lt;p&gt;We explored how questionnaires like the VISQ can be improved and validated, and potentially be adapted for clinical contexts. We also dipped our toes into the fascinating world of schizophrenia and predictive brain models.&lt;/p&gt;
&lt;p&gt;It wasn&amp;rsquo;t all work, though - Summer&amp;rsquo;s Halloween-themed biscuits added a festive touch to the proceedings. The enthusiasm in the room was palpable, with every member eager to contribute.&lt;/p&gt;
&lt;p&gt;This successful start sets the stage for an exciting term ahead. Each STAR will have the chance to shine, engaging with a diverse range of topics and lively debates. Stay tuned for more updates!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exciting Funding News!</title>
      <link>http://localhost:1313/post/20241001-apex-award/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/post/20241001-apex-award/</guid>
      <description>&lt;p&gt;We are thrilled to announce that our lab has been awarded &lt;a href=&#34;https://royalsociety.org/news/2024/09/apex-awards/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;an APEX Award by the Royal Society&lt;/a&gt; for an exciting project towards EEG Classification of Auditory Verbal Hallucinations.&lt;/p&gt;
&lt;p&gt;Our research aims to advance the understanding and detection of internal speech experiences akin to auditory verbal hallucinations (AVHs) by combining electroencephalography (EEG) with explainable machine learning. This cross-disciplinary approach brings together experts from neuroscience, psychology, and computer science to develop a potentially game-changing method for monitoring and treating AVHs.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re excited about the possibilities this project opens up and the potential to improve the lives of those affected by AVHs. Stay tuned for updates as we embark on this exciting new chapter in our research!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transcranial electrical stimulation modulates emotional experience and metabolites in the prefrontal cortex in a donation task</title>
      <link>http://localhost:1313/publication/2024-mbmcabmhmmp-scirep/</link>
      <pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2024-mbmcabmhmmp-scirep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Emotion processing in concrete and abstract words: Evidence from eye fixations during reading</title>
      <link>http://localhost:1313/publication/2024-ysbms-cognemo/</link>
      <pubDate>Wed, 05 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2024-ysbms-cognemo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bridging phenomenology and neural mechanisms of inner speech: ALE meta-analysis on egocentricity and spontaneity in a dual-mechanistic framework</title>
      <link>http://localhost:1313/publication/2023-ppy-neuroimage/</link>
      <pubDate>Fri, 29 Sep 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2023-ppy-neuroimage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Investigating the lateralisation of experimentally induced auditory verbal hallucinations</title>
      <link>http://localhost:1313/publication/2023-mcpky-fin/</link>
      <pubDate>Thu, 06 Jul 2023 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2023-mcpky-fin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What can size tell us about abstract conceptual processing?</title>
      <link>http://localhost:1313/publication/2022-yts-jml/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2022-yts-jml/</guid>
      <description></description>
    </item>
    
    <item>
      <title>People</title>
      <link>http://localhost:1313/people/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/people/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reading direct speech quotes increases theta phase-locking: Evidence for cortical tracking of inner speech?</title>
      <link>http://localhost:1313/publication/2021-ytbk-neuroimage/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2021-ytbk-neuroimage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mental simulations of phonological representations are causally linked to silent reading of direct versus indirect speech</title>
      <link>http://localhost:1313/publication/2021-y-jocognition/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2021-y-jocognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Processing speech and thoughts during silent reading: Direct reference effects for speech by fictional characters in voice-selective auditory cortex and a Theory-of-Mind network</title>
      <link>http://localhost:1313/publication/2020-ambmyf-jocn/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2020-ambmyf-jocn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Glasgow Norms: Ratings of 5,500 words on nine scales</title>
      <link>http://localhost:1313/publication/2019-skbys-brm/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2019-skbys-brm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Direct speech quotations promote low relative-clause attachment in silent reading of English</title>
      <link>http://localhost:1313/publication/2018-ys-cognition/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2018-ys-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>‘It’s hard to write a good article’: The online comprehension of excuses as indirect replies</title>
      <link>http://localhost:1313/publication/2018-swlyh-qjep/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2018-swlyh-qjep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Comprehension of indirect requests is influenced by their degree of imposition</title>
      <link>http://localhost:1313/publication/2018-slwyh-discourseprocesses/</link>
      <pubDate>Sat, 17 Feb 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2018-slwyh-discourseprocesses/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Differential emotional processing in concrete and abstract words</title>
      <link>http://localhost:1313/publication/2018-ykbsos-jeplmc/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2018-ykbsos-jeplmc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Testing the limits of contextual constraint: Interactions with word frequency and parafoveal preview during fluent reading</title>
      <link>http://localhost:1313/publication/2018-shsyo-qjep/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2018-shsyo-qjep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Walking blindfolded unveils unique contributions of behavioural approach and inhibition to lateral spatial bias</title>
      <link>http://localhost:1313/publication/2016-wavy-cognition/</link>
      <pubDate>Mon, 01 Feb 2016 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2016-wavy-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Emotion word processing: Does mood make a difference?</title>
      <link>http://localhost:1313/publication/2015-ssyto-frontierpsych/</link>
      <pubDate>Mon, 24 Aug 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2015-ssyto-frontierpsych/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inner voice experiences during processing of direct and indirect speech</title>
      <link>http://localhost:1313/publication/2015-ys-eaipisp/</link>
      <pubDate>Wed, 24 Jun 2015 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2015-ys-eaipisp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Familiarity with interest breeds gossip: Contributions of emotion, expectation, and reputation</title>
      <link>http://localhost:1313/publication/2014-ysmos-plosone/</link>
      <pubDate>Wed, 13 Aug 2014 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2014-ysmos-plosone/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Semantic size of abstract concepts: It gets emotional when you can’t see it</title>
      <link>http://localhost:1313/publication/2013-yvwsos-plosone/</link>
      <pubDate>Wed, 25 Sep 2013 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2013-yvwsos-plosone/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain ‘talks over’ boring quotes: Top-down activation of voice-selective areas while listening to monotonous direct speech quotations</title>
      <link>http://localhost:1313/publication/2012-ybs-neuroimage/</link>
      <pubDate>Sun, 15 Apr 2012 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2012-ybs-neuroimage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contextual modulation of reading rate for direct versus indirect speech quotations</title>
      <link>http://localhost:1313/publication/2011-ys-cognition/</link>
      <pubDate>Thu, 01 Dec 2011 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2011-ys-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Silent reading of direct versus indirect speech activates voice-selective areas in the auditory cortex</title>
      <link>http://localhost:1313/publication/2011-ybs-jocn/</link>
      <pubDate>Sat, 01 Oct 2011 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/publication/2011-ybs-jocn/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
