<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LISN Lab</title>
    <link>https://lisn-lab.org/</link>
      <atom:link href="https://lisn-lab.org/index.xml" rel="self" type="application/rss+xml" />
    <description>LISN Lab</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Mon, 24 Oct 2022 00:00:00 +0000</lastBuildDate>
    <image>
      <url>https://lisn-lab.org/media/icon_hu_efe3ed8cd119c4a9.png</url>
      <title>LISN Lab</title>
      <link>https://lisn-lab.org/</link>
    </image>
    
    <item>
      <title>Language</title>
      <link>https://lisn-lab.org/research/language/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/research/language/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#abstract-concepts&#34;&gt;Abstract Concepts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#structural-processing&#34;&gt;Structural Processing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#eye-movements-in-reading&#34;&gt;Eye Movements in Reading&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#language-and-emotion&#34;&gt;Language and Emotion&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;p&gt;At LISN, we investigate language processing through multiple complementary lenses, from fundamental cognitive mechanisms to complex emotional interactions. Our research spans four key areas: the representation of abstract concepts, structural processing within and across languages, eye movements during reading, and the interaction between language and emotion. Through this multi-faceted approach, we aim to develop a comprehensive understanding of how humans process, comprehend, and experience language. Our work combines diverse methodologies - from precise eye-tracking measurements to cognitive-behavioral studies - enabling us to examine language processing at various levels of analysis.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;abstract-concepts&#34;&gt;Abstract Concepts&lt;/h2&gt;
&lt;p&gt;Abstract concepts like &amp;ldquo;love&amp;rdquo; or &amp;ldquo;trust&amp;rdquo; pose a unique challenge in cognitive science. Unlike concrete concepts such as &amp;ldquo;red,&amp;rdquo; which derive meaning from direct sensory experiences, abstract concepts lack physical referents. This absence raises questions about how such concepts are represented in the mind and complicates the prevailing &amp;rsquo;embodied&amp;rsquo; theory of concept representation, which suggests that concepts gain meaning through bodily experiences.&lt;/p&gt;
&lt;p&gt;At LISN, we tackle these challenges by exploring alternative grounding for abstract concepts. We investigate whether emotional or metaphorical experiences provide the basis for understanding abstract words. For example, &amp;rsquo;trust&amp;rsquo; is often considered a &amp;lsquo;big&amp;rsquo; concept because it elicits strong emotions &lt;a href=&#34;https://lisn-lab.org/publication/2013-YVWSOS-PlosONE&#34;&gt;(Yao et al., 2013)&lt;/a&gt; and is metaphorically associated with large objects like &amp;lsquo;castle&amp;rsquo; or &amp;lsquo;cathedral&amp;rsquo; &lt;a href=&#34;https://lisn-lab.org/publication/2022-YTS-JML&#34;&gt;(Yao, Taylor, &amp;amp; Sereno, 2022)&lt;/a&gt;. Our research also examines the possibility that abstract concepts have a more episodic and context-dependent grounding compared to concrete ones. For instance, the concept of &amp;rsquo;love&amp;rsquo; can vary significantly depending on the context, such as a romantic dinner or a care home, unlike more concrete concepts like &amp;lsquo;cat,&amp;rsquo; which consistently evoke features like fur and paws. We extend this inquiry to understand how embodied experiences influence language comprehension across various contexts and life stages.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;structural-processing&#34;&gt;Structural Processing&lt;/h2&gt;
&lt;p&gt;Structural processing in language is a complex cognitive function that extends beyond mere syntax. It involves breaking down sentences into components such as subjects, verbs, and objects, and understanding their interrelationships to extract meaning. This function also intersects with other cognitive domains like prosody - the intonation in spoken sentences - and arithmetic operations, highlighting its role as a domain-general mechanism crucial for structuring language, cognition, and communication.&lt;/p&gt;
&lt;p&gt;At LISN, our focus is twofold. First, we explore the link between implicit prosody in reading, commonly known as &amp;ldquo;inner speech,&amp;rdquo; and syntactic processing. This helps us understand how the &amp;lsquo;melody&amp;rsquo; of language in our minds influences sentence interpretation &lt;a href=&#34;https://lisn-lab.org/publication/2018-YS-Cognition&#34;&gt;(Yao &amp;amp; Scheepers, 2018)&lt;/a&gt;. Second, we study how sentence structures in different languages affect cognition among their speakers. For example, Chinese sentences often omit subjects and focus on topics, whereas English sentences require subjects and emphasise them. This difference could lead to varying attentional focuses and mental representations. We also examine the contrasting structures between left-branching languages like Chinese and right-branching languages like English, suggesting different structural hierarchies between languages. Through these investigations, we aim to untangle the complexities of structural processing and its influence on cognition and communication.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;eye-movements-in-reading&#34;&gt;Eye Movements in Reading&lt;/h2&gt;
&lt;p&gt;Eye movements in reading offer a rich data source for understanding cognitive processes such as attention, memory, and language comprehension. Captured through eye-tracking technology, these movements include quick jumps called saccades and brief pauses known as fixations, where most information absorption takes place. Factors like text complexity and reader familiarity affect the duration of these fixations and the length of saccades. The parafoveal region of the eye also provides a &amp;lsquo;preview&amp;rsquo; of upcoming words during saccades, facilitating smoother reading. Lexical variables such as word frequency, predictability, and orthography further influence these eye movements, offering insights into ocular control and cognitive processes in reading.&lt;/p&gt;
&lt;p&gt;At LISN, we engage in targeted research projects to explore this complex landscape. For instance, one study examines the interaction between word frequency and contextual predictability in relation to parafoveal preview, aiming to understand their combined impact on fixation durations &lt;a href=&#34;https://lisn-lab.org/publication/2018-SWLYH-QJEP&#34;&gt;(Sereno et al., 2018)&lt;/a&gt;. Another research line investigates how altering the perceptual quality of the parafoveal preview might affect the processing of the previewed word&amp;rsquo;s spelling, subsequently influencing lexical selection in later fixations. Through these studies, LISN aims to clarify the multifaceted factors that influence eye movements in reading, thereby enriching broader theories of cognition and language processing.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;language-and-emotion&#34;&gt;Language and Emotion&lt;/h2&gt;
&lt;p&gt;The processing of emotion words involves a complex interplay between language and emotional cognition. One layer of complexity arises from the interaction between a word&amp;rsquo;s concreteness and its emotional valence. For example, concrete emotion words like &amp;ldquo;kiss&amp;rdquo; or &amp;ldquo;snake&amp;rdquo; often elicit stronger emotional and cognitive responses than abstract ones like &amp;ldquo;love&amp;rdquo; or &amp;ldquo;fear,&amp;rdquo; likely because they more easily evoke sensory experiences. Beyond this, the processing of emotion words is influenced by various factors such as the individual&amp;rsquo;s current emotional state, cultural background, and the context in which the word appears. For instance, a positive mood may facilitate the processing of positively-valenced words, while a negative mood could have the opposite effect.&lt;/p&gt;
&lt;p&gt;At LISN, we focus on these nuanced interactions. We examine how concreteness and emotional valence in word processing interact, particularly in the context of alexithymia—a condition characterised by difficulties in identifying and describing emotions &lt;a href=&#34;https://lisn-lab.org/publication/2018-YKBSOS-JEPLMC&#34;&gt;(Yao et al., 2018)&lt;/a&gt;. We also investigate how emotional experiences provide an embodied basis for understanding abstract concepts, thereby extending the &amp;rsquo;embodied cognition&amp;rsquo; framework to include emotional and abstract language. For example, the abstract concept of &amp;ldquo;freedom&amp;rdquo; may be more deeply understood through the emotional experience of relief or exhilaration &lt;a href=&#34;https://lisn-lab.org/publication/2013-YVWSOS-PlosONE&#34;&gt;(Yao et al., 2013)&lt;/a&gt;. Additionally, we explore the role of mood states in emotion word processing, investigating how they can alter the perceived emotional charge of words &lt;a href=&#34;https://lisn-lab.org/publication/2015-SSYTO-FrontierPsych&#34;&gt;(Sereno et al., 2015)&lt;/a&gt;. Through these research avenues, LISN aims to offer a comprehensive understanding of emotion word processing, enriching both theoretical frameworks and practical applications in cognitive science.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Inner Speech</title>
      <link>https://lisn-lab.org/research/innerspeech/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/research/innerspeech/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#varieties-of-inner-speech&#34;&gt;Varieties of Inner Speech&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#hearing-words-off-the-page&#34;&gt;Hearing Words off the Page&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#neural-mechanisms-of-inner-speech&#34;&gt;Neural Mechanisms of Inner Speech&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#inner-speech-in-self-consciousness&#34;&gt;Inner Speech in Self-Consciousness&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;p&gt;Inner speech represents a fundamental aspect of human cognition and consciousness, manifesting in various forms and serving multiple functions in mental life. At LISN, we investigate this phenomenon through multiple complementary approaches: examining its varieties and manifestations, studying its role in reading comprehension, mapping its neural underpinnings, and exploring its contribution to consciousness and self-awareness. This comprehensive approach allows us to build a deeper understanding of how inner speech shapes human thought and experience.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;varieties-of-inner-speech&#34;&gt;Varieties of Inner Speech&lt;/h2&gt;
&lt;p&gt;Inner speech encompasses distinct varieties, each serving unique cognitive functions. Dialogic inner speech enables internal conversations where multiple perspectives are mentally represented, while condensed inner speech operates in abbreviated thought patterns without full syntactic structure. Evaluative inner speech facilitates self-reflection and assessment, and motivational inner speech serves to regulate behavior and emotional states. These varieties differ not only in their form but also in their cognitive and behavioral impacts. Understanding these distinctions is crucial for comprehending how inner speech supports various mental processes, from problem-solving to emotional regulation.&lt;/p&gt;
&lt;p&gt;At LISN, we employ multiple complementary methods to investigate these inner speech varieties. Through experience sampling, we capture real-time manifestations of different inner speech types across various cognitive tasks. Our innovative combination of think-aloud protocols with advanced EEG analysis helps identify distinct neural signatures for different inner speech subtypes. By applying machine learning techniques to these neural patterns, we&amp;rsquo;re developing new frameworks for understanding how different forms of inner speech contribute to cognitive processing. Through these research avenues, LISN aims to establish a comprehensive taxonomy of inner speech varieties and their roles in human cognition.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;hearing-words-off-the-page&#34;&gt;Hearing Words off the Page&lt;/h2&gt;
&lt;p&gt;When reading direct speech, many people report experiencing vivid inner voices, complete with distinctive tones, accents, and emotional qualities. This phenomenon represents a specialized manifestation of inner speech that bridges written language and auditory experience. The vividness of these inner voices can vary based on factors such as emotional engagement with the text, reading proficiency, and individual differences in cognitive style. This experience often enhances text comprehension and memory retention, particularly for dialogue-rich narratives.&lt;/p&gt;
&lt;p&gt;At LISN, our research has revealed the sophisticated neural and cognitive mechanisms underlying this phenomenon. Our groundbreaking studies have demonstrated increased neural activity in the auditory cortex during silent reading of direct speech &lt;a href=&#34;https://lisn-lab.org/publication/2011-YBS-JoCN&#34;&gt;(Yao, Belin, &amp;amp; Scheepers, 2011)&lt;/a&gt;, accompanied by synchronous auditory cortical oscillations &lt;a href=&#34;https://lisn-lab.org/publication/2021-YTBK-NeuroImage&#34;&gt;(Yao et al., 2021)&lt;/a&gt;. We&amp;rsquo;ve also found that eye movements during reading align with the natural rhythm of the imagined inner voice &lt;a href=&#34;https://lisn-lab.org/publication/2011-YS-Cognition&#34;&gt;(Yao &amp;amp; Scheepers, 2011)&lt;/a&gt;. Our current research explores how early experiences of learning to read aloud might establish automatic links between text and auditory experiences, and how inner voice simulation might serve as a prosocial mechanism reinforced by the brain&amp;rsquo;s reward system &lt;a href=&#34;https://lisn-lab.org/publication/2020-AMBMYF-JoCN&#34;&gt;(Alderson-Day et al., 2020)&lt;/a&gt;.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;neural-mechanisms-of-inner-speech&#34;&gt;Neural Mechanisms of Inner Speech&lt;/h2&gt;
&lt;p&gt;The neural architecture supporting inner speech involves a sophisticated network of brain regions working in concert. This network encompasses multiple circuits, including speech production mechanisms (involving motor planning, coordination, and execution areas) and speech perception mechanisms (involving various temporal and parietal regions that support phonological and semantic processing). These core circuits interact dynamically with areas responsible for memory, attention, and emotional processing, creating a complex neural symphony that enables various forms of inner speech.&lt;/p&gt;
&lt;p&gt;At LISN, our research focuses on understanding these neural mechanisms and how they support inner speech&amp;rsquo;s diverse phenomenology. We&amp;rsquo;ve highlighted the rhythmic nature of inner speech &lt;a href=&#34;https://lisn-lab.org/publication/2025-Y-PhysLife&#34;&gt;(Yao, 2025)&lt;/a&gt; by observing increased neural activity in auditory regions associated with speech prosody &lt;a href=&#34;https://lisn-lab.org/publication/2011-YBS-JoCN&#34;&gt;(Yao, Belin, &amp;amp; Scheepers, 2011)&lt;/a&gt; and more synchronous auditory cortical oscillations &lt;a href=&#34;https://lisn-lab.org/publication/2021-YTBK-NeuroImage&#34;&gt;(Yao et al., 2021)&lt;/a&gt;. Our recent meta-analysis &lt;a href=&#34;https://lisn-lab.org/publication/2023-PPY-NeuroImage&#34;&gt;(Pratts, Pobric, &amp;amp; Yao, 2023)&lt;/a&gt; suggests that inner speech may be supported by both a motor-driven pathway involving speech production circuits and an auditory pathway engaging perceptual mechanisms, potentially underpinning different inner speech subtypes. We are also employing machine learning to identify the neural features that characterise these subtypes, aiming for a more nuanced understanding of inner speech and its role in cognition. Through these research avenues, LISN seeks to deepen our understanding of the neural mechanisms of inner speech and its various subtypes.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;inner-speech-in-self-consciousness&#34;&gt;Inner Speech in Self-Consciousness&lt;/h2&gt;
&lt;p&gt;Inner speech plays a fundamental role in human consciousness, serving as a critical bridge between thought and self-awareness. This internal dialogue shapes our sense of self, influences decision-making, and mediates between different levels of consciousness, from focused attention to mind-wandering states. The relationship between inner speech and consciousness has profound implications for understanding both normal cognitive function and various psychological conditions, where alterations in inner speech often correspond to changes in self-awareness and conscious experience.&lt;/p&gt;
&lt;p&gt;At LISN, we&amp;rsquo;re pioneering new approaches to understanding this relationship through innovative research designs. Our studies capitalise on recent discoveries about aphantasia and other individual differences in mental experience to examine how variations in inner speech abilities affect self-awareness and consciousness. Using advanced EEG techniques, we&amp;rsquo;re developing objective measures of inner speech during self-referential processing, while our machine learning algorithms are creating new frameworks for classifying brain states related to different forms of inner dialogue. This research not only advances our theoretical understanding but also has practical implications for addressing conditions like rumination, depression, and auditory verbal hallucinations, where the relationship between inner speech and consciousness becomes disturbed.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Voice Hearing</title>
      <link>https://lisn-lab.org/research/voicehearing/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/research/voicehearing/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-continuum&#34;&gt;Voice Hearing Continuum&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-as-predictions&#34;&gt;Voice Hearing as Predictions&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-transition-risks&#34;&gt;Voice Hearing Transition Risks&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#voice-hearing-interventions&#34;&gt;Voice Hearing Interventions&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;p&gt;Voice hearing research spans multiple interconnected domains, from understanding its prevalence in the general population to developing innovative interventions. At LISN, we take a comprehensive approach to studying this complex phenomenon. Our research examines voice hearing across four key areas: its existence as a continuous spectrum in the population, the critical factors influencing transition to clinical conditions, the underlying predictive mechanisms in the brain, and the development of novel therapeutic interventions. By investigating these interrelated aspects, we aim to advance both theoretical understanding and practical treatments for voice hearing experiences.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-continuum&#34;&gt;Voice Hearing Continuum&lt;/h2&gt;
&lt;p&gt;Voice hearing exists on a spectrum and is not limited to clinical populations. It involves a range of experiences, from hearing one&amp;rsquo;s name to complex dialogues, and can be distressing or benign. This natural variation in human experience has been studied through neuroscientific and psychological approaches, exploring its neural and cognitive correlates, while cultural factors also play a role. Understanding this spectrum has implications for mental health treatment, challenging associated stigma and informing therapeutic interventions.&lt;/p&gt;
&lt;p&gt;At LISN, our research focuses on cognitive abilities and biases predictive of voice hearing tendencies across this spectrum. We particularly examine signal detection theory (SDT) performance, where both nonclinical and clinical voice hearers often exhibit an externalising bias, perceiving internal voices as originating externally. Through rigorous experimental methods, we compare SDT performance among individuals to understand how this bias may be influenced by auditory verbal hallucination (AVH) proneness, variations in corollary discharge, memory inhibition, and other individual factors. Through this focus, LISN aims to offer a nuanced understanding of the cognitive mechanisms underlying the voice hearing spectrum.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-as-predictions&#34;&gt;Voice Hearing as Predictions&lt;/h2&gt;
&lt;p&gt;Voice hearing has been increasingly studied within the predictive coding framework, which describes perception as a process of hypothesis testing. In this framework, auditory verbal hallucinations (AVH) may arise from an imbalance between top-down predictions and bottom-up sensory input. This fundamental brain mechanism has been explored through various factors, such as neurotransmitter systems, cognitive biases, and socio-emotional factors. This perspective offers a generalised understanding of voice hearing and opens new avenues for prognosis, diagnosis and treatment.&lt;/p&gt;
&lt;p&gt;At LISN, we focus on experimentally manipulating predictions and sensory input to understand voice hearing better. Methods include conditioning, articulatory suppression, earworm induction, and exposure to different types of auditory noises. We assess the impacts of these manipulations on signal detection task (SDT) performance and self-reported voice hearing experiences &lt;a href=&#34;https://lisn-lab.org/publication/2023-MCPKY-FiN&#34;&gt;(Mak et al., 2023)&lt;/a&gt;. By demonstrating how voice hearing arises from natural brain processes, we aim to develop methods to characterise voice hearing tendencies across the population. This research helps us understand its prevalence and transition risks to psychosis, while contributing to broader efforts to normalize these experiences and reduce stigma, particularly in underserved communities.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-transition-risks&#34;&gt;Voice Hearing Transition Risks&lt;/h2&gt;
&lt;p&gt;The transition from voice hearing to psychosis is a critical but relatively uncommon area of study in mental health research. While many people experience voice hearing without transitioning to clinical states like psychosis, understanding the factors that contribute to this transition is crucial for early intervention. Research has identified risk factors such as frequency and distress level of voice hearing, comorbid symptoms, and environmental stressors. Neurobiological markers and the concept of a &amp;ldquo;clinical high-risk state&amp;rdquo; have also been studied to identify those at increased risk.&lt;/p&gt;
&lt;p&gt;In collaboration with the Greater Manchester Mental Health NHS Foundation Trust, LISN conducts pioneering research to understand the transition risks among nonclinical voice hearers. Our research focuses on understanding these risks as neurodevelopmental vulnerabilities, which manifest through increasingly complex voice hearing experiences. We also aim to understand the underlying cognitive and neural mechanisms that contribute to this transition. Through this targeted research, LISN seeks to offer insights into the factors that may lead to the transition from voice hearing to psychosis, with the goal of informing early intervention and prevention strategies.
&lt;br&gt;
&lt;br&gt;&lt;/p&gt;
&lt;h2 id=&#34;voice-hearing-interventions&#34;&gt;Voice Hearing Interventions&lt;/h2&gt;
&lt;p&gt;Interventions for voice hearing have evolved to include a range of approaches, from pharmacological treatments to psychological therapies like CBT and mindfulness. Advanced techniques like neurostimulation and neurofeedback offer targeted, brain-based interventions. Neurostimulation methods like TMS and tDCS modulate neural activity, while neurofeedback teaches self-regulation through real-time brain monitoring. These methods are less reliant on medication and offer the promise of more personalised treatment.&lt;/p&gt;
&lt;p&gt;At LISN, our focus is on developing an EEG-tDCS closed-loop type of online intervention for voice hearing. This innovative system uses EEG to identify voice hearing states in real-time, while tDCS provides targeted intervention to prevent escalation into psychotic episodes. While this cutting-edge approach is still under development, it represents the ultimate goal of our lab in studying voice hearing. Through this pioneering technology, LISN aims to offer a more immediate and targeted intervention, potentially revolutionising the treatment landscape for voice hearing.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Lack of mental imagery? You may be special!</title>
      <link>https://lisn-lab.org/post/20250121-aphantasia/</link>
      <pubDate>Tue, 21 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/post/20250121-aphantasia/</guid>
      <description>

&lt;details class=&#34;toc-inpage d-print-none  &#34; open&gt;
  &lt;summary class=&#34;font-weight-bold&#34;&gt;Table of Contents&lt;/summary&gt;
  &lt;nav id=&#34;TableOfContents&#34;&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&#34;#what-is-aphantasia&#34;&gt;What is Aphantasia?&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#does-aphantasia-affect-everyday-life&#34;&gt;Does Aphantasia Affect Everyday Life?&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#the-surprising-benefits-of-aphantasia&#34;&gt;The Surprising Benefits of Aphantasia&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#what-about-you&#34;&gt;What About You?&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&#34;#contributing-to-research&#34;&gt;Contributing to Research&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
&lt;/details&gt;

&lt;p&gt;Think of an apple in your mind. Can you see a red fruit with a glossy sheen, or… nothing at all? If it is the latter, then &lt;strong&gt;you may be part of 2-4% of the world’s population that are aphantasic!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Don&amp;rsquo;t worry - aphantasia isn&amp;rsquo;t a disability or medical condition. It&amp;rsquo;s simply a different way that the mind processes information and thinks.&lt;/p&gt;
&lt;h2 id=&#34;what-is-aphantasia&#34;&gt;What is Aphantasia?&lt;/h2&gt;
&lt;p&gt;Aphantasia is when your brain doesn’t form or use mental images as part of your thinking or imagination. If your mind is like a TV, for someone with Aphantasia, it is as if the screen is blank, with no shapes or colours or… anything at all.&lt;/p&gt;
&lt;p&gt;This affects even the most familiar objects. For instance, someone I interviewed said they can’t even imagine objects they use every day, such as their phone. They can think about their phone as a concept but literally cannot picture it in their head!
Aphantasia can be congenital (from birth) or acquired (developed in later life, often due to illness / injury / mental health condition) and doesn’t need diagnosing. In fact, people often don’t even realise that they are aphantasic, even though they may notice from a young age they lack the ability to form mental images.&lt;/p&gt;
&lt;p&gt;For example, in a BBC news article Niel Kenmuir said that as a child, he couldn’t fall asleep counting sheep – not because he didn’t want to, but because he simply couldn’t see the sheep in his mind! He didn’t realise this was unusual until adulthood. Indeed, many people didn’t realise until later in life that they were aphantasic, but did notice from a young age that they could not picture things in their mind like others.&lt;/p&gt;
&lt;h2 id=&#34;does-aphantasia-affect-everyday-life&#34;&gt;Does Aphantasia Affect Everyday Life?&lt;/h2&gt;
&lt;p&gt;Aphantasia rarely affects everyday life, as it doesn’t stop them from doing things.
However, Aphantasia does impact certain abilities, such as not being able to picture what book characters look like when reading, or finding arts and geometry hard because they can’t manipulate images or shapes in their mind.&lt;/p&gt;
&lt;p&gt;Some Aphantasics experience very poor visual memory – it’d be a struggle for them to recall images from significant events like wedding or their first day at school, and sometimes even to recognise faces.&lt;/p&gt;
&lt;h2 id=&#34;the-surprising-benefits-of-aphantasia&#34;&gt;The Surprising Benefits of Aphantasia&lt;/h2&gt;
&lt;p&gt;While having Aphantasia isn’t a limitation – it’s just a different way of thinking. Research suggests it may actually enhance certain cognitive abilities. People with aphantasia often excel in analytical thinking and abstract reasoning, demonstrating superior factual memory and logical problem-solving skills. Additionally, some aphantasic individuals report practical advantages, such as being less affected by traumatic visual memories or disturbing descriptions in books or movies, as they process information conceptually rather than visually.&lt;/p&gt;
&lt;h2 id=&#34;what-about-you&#34;&gt;What About You?&lt;/h2&gt;
&lt;p&gt;Are you curious about how your own mind works? Can you picture an apple? Do you have mental imagery? Have you ever wondered if you might be aphantasic? Understanding your cognitive style can provide valuable insights into how you learn, process information, and interact with the world.&lt;/p&gt;
&lt;h2 id=&#34;contributing-to-research&#34;&gt;Contributing to Research&lt;/h2&gt;
&lt;p&gt;Your experience matters to the scientific community. As part of our ongoing research into neurodiversity, we&amp;rsquo;re conducting a study on how aphantasia affects cognition.&lt;/p&gt;
&lt;p&gt;If you think you are Aphantasic and would like to contribute to our understanding of this fascinating variation in human cognition, please join our research by signing up through the link below.&lt;/p&gt;


&lt;ul class=&#34;cta-group&#34;&gt;
  
  &lt;li&gt;
    &lt;a href=&#34;https://forms.office.com/Pages/ResponsePage.aspx?id=Ec2bnHqXnE6poLxzQJAWSrFgdYO91ptHjgdJqGlvLhxUNUQ4RDZONVdCNjlGVUJHSU1HVVZXT1E5OC4u&#34;  class=&#34;btn btn-primary px-3 py-3&#34;&gt;Yay! Sign Me Up!&lt;/a&gt;
  &lt;/li&gt;
  
  
&lt;/ul&gt;

</description>
    </item>
    
    <item>
      <title>It&#39;s about time: Rhythmic foundations of inner thought</title>
      <link>https://lisn-lab.org/publication/2025-y-physlife/</link>
      <pubDate>Mon, 06 Jan 2025 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2025-y-physlife/</guid>
      <description></description>
    </item>
    
    <item>
      <title>STARS Squad Kicks Off Journal Club with a Bang!</title>
      <link>https://lisn-lab.org/post/20241030-stars-journalclub/</link>
      <pubDate>Wed, 30 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/post/20241030-stars-journalclub/</guid>
      <description>&lt;p&gt;Our new STARS squad launched their first journal club this week, and it was a hit! Maisie led an engaging discussion on the Variety of Inner Speech Questionnaire-Revised, sparking interesting conversations about inner speech, cultural norms, and individual experiences.&lt;/p&gt;
&lt;p&gt;We explored how questionnaires like the VISQ can be improved and validated, and potentially be adapted for clinical contexts. We also dipped our toes into the fascinating world of schizophrenia and predictive brain models.&lt;/p&gt;
&lt;p&gt;It wasn&amp;rsquo;t all work, though - Summer&amp;rsquo;s Halloween-themed biscuits added a festive touch to the proceedings. The enthusiasm in the room was palpable, with every member eager to contribute.&lt;/p&gt;
&lt;p&gt;This successful start sets the stage for an exciting term ahead. Each STAR will have the chance to shine, engaging with a diverse range of topics and lively debates. Stay tuned for more updates!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exciting Funding News!</title>
      <link>https://lisn-lab.org/post/20241001-apex-award/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/post/20241001-apex-award/</guid>
      <description>&lt;p&gt;We are thrilled to announce that our lab has been awarded &lt;a href=&#34;https://royalsociety.org/news/2024/09/apex-awards/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;an APEX Award by the Royal Society&lt;/a&gt; for an exciting project towards EEG Classification of Auditory Verbal Hallucinations.&lt;/p&gt;
&lt;p&gt;Our research aims to advance the understanding and detection of internal speech experiences akin to auditory verbal hallucinations (AVHs) by combining electroencephalography (EEG) with explainable machine learning. This cross-disciplinary approach brings together experts from neuroscience, psychology, and computer science to develop a potentially game-changing method for monitoring and treating AVHs.&lt;/p&gt;
&lt;p&gt;We&amp;rsquo;re excited about the possibilities this project opens up and the potential to improve the lives of those affected by AVHs. Stay tuned for updates as we embark on this exciting new chapter in our research!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Transcranial electrical stimulation modulates emotional experience and metabolites in the prefrontal cortex in a donation task</title>
      <link>https://lisn-lab.org/publication/2024-mbmcabmhmmp-scirep/</link>
      <pubDate>Thu, 20 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2024-mbmcabmhmmp-scirep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Emotion processing in concrete and abstract words: Evidence from eye fixations during reading</title>
      <link>https://lisn-lab.org/publication/2024-ysbms-cognemo/</link>
      <pubDate>Wed, 05 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2024-ysbms-cognemo/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Bridging phenomenology and neural mechanisms of inner speech: ALE meta-analysis on egocentricity and spontaneity in a dual-mechanistic framework</title>
      <link>https://lisn-lab.org/publication/2023-ppy-neuroimage/</link>
      <pubDate>Fri, 29 Sep 2023 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2023-ppy-neuroimage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Investigating the lateralisation of experimentally induced auditory verbal hallucinations</title>
      <link>https://lisn-lab.org/publication/2023-mcpky-fin/</link>
      <pubDate>Thu, 06 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2023-mcpky-fin/</guid>
      <description></description>
    </item>
    
    <item>
      <title>What can size tell us about abstract conceptual processing?</title>
      <link>https://lisn-lab.org/publication/2022-yts-jml/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2022-yts-jml/</guid>
      <description></description>
    </item>
    
    <item>
      <title>People</title>
      <link>https://lisn-lab.org/people/</link>
      <pubDate>Mon, 24 Oct 2022 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/people/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Reading direct speech quotes increases theta phase-locking: Evidence for cortical tracking of inner speech?</title>
      <link>https://lisn-lab.org/publication/2021-ytbk-neuroimage/</link>
      <pubDate>Fri, 01 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2021-ytbk-neuroimage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Mental simulations of phonological representations are causally linked to silent reading of direct versus indirect speech</title>
      <link>https://lisn-lab.org/publication/2021-y-jocognition/</link>
      <pubDate>Fri, 08 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2021-y-jocognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Processing speech and thoughts during silent reading: Direct reference effects for speech by fictional characters in voice-selective auditory cortex and a Theory-of-Mind network</title>
      <link>https://lisn-lab.org/publication/2020-ambmyf-jocn/</link>
      <pubDate>Tue, 01 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2020-ambmyf-jocn/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The Glasgow Norms: Ratings of 5,500 words on nine scales</title>
      <link>https://lisn-lab.org/publication/2019-skbys-brm/</link>
      <pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2019-skbys-brm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Direct speech quotations promote low relative-clause attachment in silent reading of English</title>
      <link>https://lisn-lab.org/publication/2018-ys-cognition/</link>
      <pubDate>Sun, 15 Jul 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-ys-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>‘It’s hard to write a good article’: The online comprehension of excuses as indirect replies</title>
      <link>https://lisn-lab.org/publication/2018-swlyh-qjep/</link>
      <pubDate>Fri, 01 Jun 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-swlyh-qjep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Comprehension of indirect requests is influenced by their degree of imposition</title>
      <link>https://lisn-lab.org/publication/2018-slwyh-discourseprocesses/</link>
      <pubDate>Sat, 17 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-slwyh-discourseprocesses/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Differential emotional processing in concrete and abstract words</title>
      <link>https://lisn-lab.org/publication/2018-ykbsos-jeplmc/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-ykbsos-jeplmc/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Testing the limits of contextual constraint: Interactions with word frequency and parafoveal preview during fluent reading</title>
      <link>https://lisn-lab.org/publication/2018-shsyo-qjep/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2018-shsyo-qjep/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Walking blindfolded unveils unique contributions of behavioural approach and inhibition to lateral spatial bias</title>
      <link>https://lisn-lab.org/publication/2016-wavy-cognition/</link>
      <pubDate>Mon, 01 Feb 2016 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2016-wavy-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Emotion word processing: Does mood make a difference?</title>
      <link>https://lisn-lab.org/publication/2015-ssyto-frontierpsych/</link>
      <pubDate>Mon, 24 Aug 2015 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2015-ssyto-frontierpsych/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Inner voice experiences during processing of direct and indirect speech</title>
      <link>https://lisn-lab.org/publication/2015-ys-eaipisp/</link>
      <pubDate>Wed, 24 Jun 2015 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2015-ys-eaipisp/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Familiarity with interest breeds gossip: Contributions of emotion, expectation, and reputation</title>
      <link>https://lisn-lab.org/publication/2014-ysmos-plosone/</link>
      <pubDate>Wed, 13 Aug 2014 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2014-ysmos-plosone/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Semantic size of abstract concepts: It gets emotional when you can’t see it</title>
      <link>https://lisn-lab.org/publication/2013-yvwsos-plosone/</link>
      <pubDate>Wed, 25 Sep 2013 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2013-yvwsos-plosone/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Brain ‘talks over’ boring quotes: Top-down activation of voice-selective areas while listening to monotonous direct speech quotations</title>
      <link>https://lisn-lab.org/publication/2012-ybs-neuroimage/</link>
      <pubDate>Sun, 15 Apr 2012 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2012-ybs-neuroimage/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Contextual modulation of reading rate for direct versus indirect speech quotations</title>
      <link>https://lisn-lab.org/publication/2011-ys-cognition/</link>
      <pubDate>Thu, 01 Dec 2011 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2011-ys-cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Silent reading of direct versus indirect speech activates voice-selective areas in the auditory cortex</title>
      <link>https://lisn-lab.org/publication/2011-ybs-jocn/</link>
      <pubDate>Sat, 01 Oct 2011 00:00:00 +0000</pubDate>
      <guid>https://lisn-lab.org/publication/2011-ybs-jocn/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
